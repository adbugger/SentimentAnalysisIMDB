{'word_context': 15, 'word_embed_size': 500, 'word_conv_units': 50, 'hidden_units': 5, 'dropout': True, 'batch_size': 500}
2482
train set done
test set done
[  1,     1] loss: 0.97240
[  1,   501] loss: 2.29127
[  1,  1001] loss: 7.62649
[  1,  1501] loss: 2.91585
[  1,  2001] loss: 2.37635
[  1,  2501] loss: 3.27436
[  1,  3001] loss: 2.26456
[  1,  3501] loss: 1.94584
[  1,  4001] loss: 1.98884
[  1,  4501] loss: 1.37016
[  1,  5001] loss: 1.38588
[  1,  5501] loss: 1.30288
[  1,  6001] loss: 1.17374
[  1,  6501] loss: 1.08541
[  1,  7001] loss: 0.96767
[  1,  7501] loss: 0.99579
[  1,  8001] loss: 0.90226
[  1,  8501] loss: 0.98154
[  1,  9001] loss: 0.89577
[  1,  9501] loss: 0.89321
[  1, 10001] loss: 0.90641
[  1, 10501] loss: 0.96726
[  1, 11001] loss: 1.01558
[  1, 11501] loss: 0.93053
[  1, 12001] loss: 0.87946
[  1, 12501] loss: 0.82443
[  1, 13001] loss: 0.83510
[  1, 13501] loss: 0.83924
[  1, 14001] loss: 0.90576
[  1, 14501] loss: 0.85273
[  1, 15001] loss: 0.79880
[  1, 15501] loss: 0.79943
[  1, 16001] loss: 0.84609
[  1, 16501] loss: 0.83047
[  1, 17001] loss: 0.80232
[  1, 17501] loss: 0.77596
[  1, 18001] loss: 0.82468
[  1, 18501] loss: 0.85126
[  1, 19001] loss: 0.83677
[  1, 19501] loss: 0.83660
[  1, 20001] loss: 0.84514
[  1, 20501] loss: 0.89599
[  1, 21001] loss: 0.83967
[  1, 21501] loss: 0.82433
[  1, 22001] loss: 0.86523
[  1, 22501] loss: 0.91425
[  1, 23001] loss: 0.83377
[  1, 23501] loss: 0.82695
[  1, 24001] loss: 0.80781
[  1, 24501] loss: 0.74186
[  2,     1] loss: 0.73320
[  2,   501] loss: 0.75748
[  2,  1001] loss: 0.72170
[  2,  1501] loss: 0.76828
[  2,  2001] loss: 0.80030
[  2,  2501] loss: 0.80550
[  2,  3001] loss: 0.80065
[  2,  3501] loss: 0.72768
[  2,  4001] loss: 0.71927
[  2,  4501] loss: 0.77104
[  2,  5001] loss: 0.73776
[  2,  5501] loss: 0.76640
[  2,  6001] loss: 0.71775
[  2,  6501] loss: 0.69047
[  2,  7001] loss: 0.73220
[  2,  7501] loss: 0.74631
[  2,  8001] loss: 0.73320
[  2,  8501] loss: 0.66011
[  2,  9001] loss: 0.75284
[  2,  9501] loss: 0.71118
[  2, 10001] loss: 0.69513
[  2, 10501] loss: 0.69272
[  2, 11001] loss: 0.69360
[  2, 11501] loss: 0.65821
[  2, 12001] loss: 0.67530
[  2, 12501] loss: 0.71833
[  2, 13001] loss: 0.68072
[  2, 13501] loss: 0.70206
[  2, 14001] loss: 0.69470
[  2, 14501] loss: 0.71579
[  2, 15001] loss: 0.77965
[  2, 15501] loss: 0.80647
[  2, 16001] loss: 0.75942
[  2, 16501] loss: 0.69717
[  2, 17001] loss: 0.68739
[  2, 17501] loss: 0.71763
[  2, 18001] loss: 0.67296
[  2, 18501] loss: 0.68461
[  2, 19001] loss: 0.67199
[  2, 19501] loss: 0.69176
[  2, 20001] loss: 0.71138
[  2, 20501] loss: 0.67597
[  2, 21001] loss: 0.65455
[  2, 21501] loss: 0.68998
[  2, 22001] loss: 0.68669
[  2, 22501] loss: 0.67756
[  2, 23001] loss: 0.66416
[  2, 23501] loss: 0.72180
[  2, 24001] loss: 0.71405
[  2, 24501] loss: 0.71560
Finished training
Accuracy on train: 0.65436
Accuracy on test: 0.54326
