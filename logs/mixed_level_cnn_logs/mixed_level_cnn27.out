{'word_context': 51, 'word_embed_size': 200, 'word_conv_units': 10, 'hidden_units': 5, 'dropout': False, 'batch_size': 500}
2482
train set done
test set done
[  1,     1] loss: 0.76225
[  1,   501] loss: 2.77043
[  1,  1001] loss: 0.74654
[  1,  1501] loss: 0.76969
[  1,  2001] loss: 0.94609
[  1,  2501] loss: 0.98411
[  1,  3001] loss: 0.89064
[  1,  3501] loss: 0.90467
[  1,  4001] loss: 0.82478
[  1,  4501] loss: 0.85398
[  1,  5001] loss: 0.86885
[  1,  5501] loss: 0.84697
[  1,  6001] loss: 0.82583
[  1,  6501] loss: 0.80608
[  1,  7001] loss: 0.81908
[  1,  7501] loss: 0.85743
[  1,  8001] loss: 0.88607
[  1,  8501] loss: 0.84890
[  1,  9001] loss: 0.78185
[  1,  9501] loss: 0.75834
[  1, 10001] loss: 0.76947
[  1, 10501] loss: 0.74854
[  1, 11001] loss: 0.73737
[  1, 11501] loss: 0.72156
[  1, 12001] loss: 0.70225
[  1, 12501] loss: 0.71350
[  1, 13001] loss: 0.67682
[  1, 13501] loss: 0.67637
[  1, 14001] loss: 0.69692
[  1, 14501] loss: 0.69908
[  1, 15001] loss: 0.72060
[  1, 15501] loss: 0.77293
[  1, 16001] loss: 0.79318
[  1, 16501] loss: 0.78730
[  1, 17001] loss: 0.80672
[  1, 17501] loss: 0.81728
[  1, 18001] loss: 0.75435
[  1, 18501] loss: 0.70080
[  1, 19001] loss: 0.71452
[  1, 19501] loss: 0.74102
[  1, 20001] loss: 0.77009
[  1, 20501] loss: 0.77214
[  1, 21001] loss: 0.74016
[  1, 21501] loss: 0.77020
[  1, 22001] loss: 0.74983
[  1, 22501] loss: 0.77878
[  1, 23001] loss: 0.77310
[  1, 23501] loss: 0.80991
[  1, 24001] loss: 0.83058
[  1, 24501] loss: 0.78230
[  2,     1] loss: 0.74211
[  2,   501] loss: 0.72851
[  2,  1001] loss: 0.69329
[  2,  1501] loss: 0.72981
[  2,  2001] loss: 0.73766
[  2,  2501] loss: 0.71110
[  2,  3001] loss: 0.69387
[  2,  3501] loss: 0.66123
[  2,  4001] loss: 0.68156
[  2,  4501] loss: 0.65189
[  2,  5001] loss: 0.64431
[  2,  5501] loss: 0.64471
[  2,  6001] loss: 0.66161
[  2,  6501] loss: 0.63431
[  2,  7001] loss: 0.63823
[  2,  7501] loss: 0.63882
[  2,  8001] loss: 0.65263
[  2,  8501] loss: 0.66766
[  2,  9001] loss: 0.74541
[  2,  9501] loss: 0.72616
[  2, 10001] loss: 0.78112
[  2, 10501] loss: 0.73759
[  2, 11001] loss: 0.74077
[  2, 11501] loss: 0.66656
[  2, 12001] loss: 0.64938
[  2, 12501] loss: 0.68508
[  2, 13001] loss: 0.66088
[  2, 13501] loss: 0.61406
[  2, 14001] loss: 0.65472
[  2, 14501] loss: 0.66566
[  2, 15001] loss: 0.66177
[  2, 15501] loss: 0.68595
[  2, 16001] loss: 0.69635
[  2, 16501] loss: 0.65518
[  2, 17001] loss: 0.68542
[  2, 17501] loss: 0.66835
[  2, 18001] loss: 0.65596
[  2, 18501] loss: 0.58679
[  2, 19001] loss: 0.58368
[  2, 19501] loss: 0.59443
[  2, 20001] loss: 0.61237
[  2, 20501] loss: 0.58330
[  2, 21001] loss: 0.56406
[  2, 21501] loss: 0.61935
[  2, 22001] loss: 0.59533
[  2, 22501] loss: 0.74235
[  2, 23001] loss: 0.89479
[  2, 23501] loss: 0.83744
[  2, 24001] loss: 0.81086
[  2, 24501] loss: 0.83140
Finished training
Accuracy on train: 0.58976
Accuracy on test: 0.53948
