{'word_context': 31, 'word_embed_size': 200, 'word_conv_units': 10, 'hidden_units': 50, 'dropout': False, 'batch_size': 500}
2482
train set done
test set done
[  1,     1] loss: 0.73737
[  1,   501] loss: 2.54476
[  1,  1001] loss: 0.91688
[  1,  1501] loss: 0.91369
[  1,  2001] loss: 0.83620
[  1,  2501] loss: 0.81369
[  1,  3001] loss: 0.81521
[  1,  3501] loss: 0.78315
[  1,  4001] loss: 0.72442
[  1,  4501] loss: 0.69295
[  1,  5001] loss: 0.69992
[  1,  5501] loss: 0.71223
[  1,  6001] loss: 0.74139
[  1,  6501] loss: 0.76473
[  1,  7001] loss: 0.74180
[  1,  7501] loss: 0.70510
[  1,  8001] loss: 0.68355
[  1,  8501] loss: 0.72913
[  1,  9001] loss: 0.75846
[  1,  9501] loss: 0.83387
[  1, 10001] loss: 0.87829
[  1, 10501] loss: 0.82399
[  1, 11001] loss: 0.78552
[  1, 11501] loss: 0.76304
[  1, 12001] loss: 0.71292
[  1, 12501] loss: 0.72441
[  1, 13001] loss: 0.74257
[  1, 13501] loss: 0.71683
[  1, 14001] loss: 0.72284
[  1, 14501] loss: 0.70490
[  1, 15001] loss: 0.76815
[  1, 15501] loss: 0.79163
[  1, 16001] loss: 0.81724
[  1, 16501] loss: 0.83595
[  1, 17001] loss: 0.77500
[  1, 17501] loss: 0.75551
[  1, 18001] loss: 0.71379
[  1, 18501] loss: 0.70555
[  1, 19001] loss: 0.68644
[  1, 19501] loss: 0.67984
[  1, 20001] loss: 0.66876
[  1, 20501] loss: 0.67050
[  1, 21001] loss: 0.72626
[  1, 21501] loss: 0.71491
[  1, 22001] loss: 0.70349
[  1, 22501] loss: 0.75855
[  1, 23001] loss: 0.76252
[  1, 23501] loss: 0.76003
[  1, 24001] loss: 0.73142
[  1, 24501] loss: 0.75128
[  2,     1] loss: 0.68863
[  2,   501] loss: 0.70802
[  2,  1001] loss: 0.66168
[  2,  1501] loss: 0.67126
[  2,  2001] loss: 0.66626
[  2,  2501] loss: 0.69220
[  2,  3001] loss: 0.69795
[  2,  3501] loss: 0.71707
[  2,  4001] loss: 0.66047
[  2,  4501] loss: 0.64287
[  2,  5001] loss: 0.64735
[  2,  5501] loss: 0.68698
[  2,  6001] loss: 0.72532
[  2,  6501] loss: 0.69640
[  2,  7001] loss: 0.65926
[  2,  7501] loss: 0.63109
[  2,  8001] loss: 0.60424
[  2,  8501] loss: 0.63755
[  2,  9001] loss: 0.61105
[  2,  9501] loss: 0.61742
[  2, 10001] loss: 0.64448
[  2, 10501] loss: 0.64777
[  2, 11001] loss: 0.66266
[  2, 11501] loss: 0.65209
[  2, 12001] loss: 0.67243
[  2, 12501] loss: 0.68301
[  2, 13001] loss: 0.72671
[  2, 13501] loss: 0.68775
[  2, 14001] loss: 0.67286
[  2, 14501] loss: 0.62460
[  2, 15001] loss: 0.67150
[  2, 15501] loss: 0.66805
[  2, 16001] loss: 0.67921
[  2, 16501] loss: 0.70428
[  2, 17001] loss: 0.66627
[  2, 17501] loss: 0.67868
[  2, 18001] loss: 0.61994
[  2, 18501] loss: 0.63194
[  2, 19001] loss: 0.62039
[  2, 19501] loss: 0.60831
[  2, 20001] loss: 0.60731
[  2, 20501] loss: 0.60974
[  2, 21001] loss: 0.64571
[  2, 21501] loss: 0.63444
[  2, 22001] loss: 0.60556
[  2, 22501] loss: 0.64164
[  2, 23001] loss: 0.63131
[  2, 23501] loss: 0.61592
[  2, 24001] loss: 0.57716
[  2, 24501] loss: 0.60230
Finished training
Accuracy on train: 0.71876
Accuracy on test: 0.57448
