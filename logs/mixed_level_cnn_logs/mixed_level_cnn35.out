{'word_context': 31, 'word_embed_size': 200, 'word_conv_units': 500, 'hidden_units': 5, 'dropout': False, 'batch_size': 500}
2482
train set done
test set done
[  1,     1] loss: 0.78458
[  1,   501] loss: 8.78619
[  1,  1001] loss: 4.33787
[  1,  1501] loss: 4.66894
[  1,  2001] loss: 2.64915
[  1,  2501] loss: 4.19513
[  1,  3001] loss: 2.55005
[  1,  3501] loss: 2.70298
[  1,  4001] loss: 1.59439
[  1,  4501] loss: 2.99325
[  1,  5001] loss: 1.63662
[  1,  5501] loss: 1.88270
[  1,  6001] loss: 1.63530
[  1,  6501] loss: 1.71781
[  1,  7001] loss: 0.92649
[  1,  7501] loss: 1.29450
[  1,  8001] loss: 1.27060
[  1,  8501] loss: 1.13820
[  1,  9001] loss: 1.11114
[  1,  9501] loss: 1.01248
[  1, 10001] loss: 0.93256
[  1, 10501] loss: 0.86337
[  1, 11001] loss: 0.80635
[  1, 11501] loss: 0.84233
[  1, 12001] loss: 0.83237
[  1, 12501] loss: 0.91149
[  1, 13001] loss: 0.95475
[  1, 13501] loss: 0.90938
[  1, 14001] loss: 0.79807
[  1, 14501] loss: 0.78126
[  1, 15001] loss: 0.77767
[  1, 15501] loss: 0.73335
[  1, 16001] loss: 0.71116
[  1, 16501] loss: 0.68835
[  1, 17001] loss: 0.68653
[  1, 17501] loss: 0.68654
[  1, 18001] loss: 0.68973
[  1, 18501] loss: 0.67888
[  1, 19001] loss: 0.67231
[  1, 19501] loss: 0.65220
[  1, 20001] loss: 0.64726
[  1, 20501] loss: 0.66664
[  1, 21001] loss: 0.70541
[  1, 21501] loss: 0.77623
[  1, 22001] loss: 0.87103
[  1, 22501] loss: 0.89965
[  1, 23001] loss: 0.78470
[  1, 23501] loss: 0.78670
[  1, 24001] loss: 0.77952
[  1, 24501] loss: 0.88365
[  2,     1] loss: 0.74501
[  2,   501] loss: 0.71425
[  2,  1001] loss: 0.67468
[  2,  1501] loss: 0.66941
[  2,  2001] loss: 0.61987
[  2,  2501] loss: 0.61170
[  2,  3001] loss: 0.59236
[  2,  3501] loss: 0.56170
[  2,  4001] loss: 0.56437
[  2,  4501] loss: 0.63461
[  2,  5001] loss: 0.82236
[  2,  5501] loss: 1.04431
[  2,  6001] loss: 0.91045
[  2,  6501] loss: 0.75238
[  2,  7001] loss: 0.84062
[  2,  7501] loss: 0.71407
[  2,  8001] loss: 0.73525
[  2,  8501] loss: 0.71895
[  2,  9001] loss: 0.68800
[  2,  9501] loss: 0.68163
[  2, 10001] loss: 0.67997
[  2, 10501] loss: 0.66482
[  2, 11001] loss: 0.65790
[  2, 11501] loss: 0.62520
[  2, 12001] loss: 0.60237
[  2, 12501] loss: 0.60119
[  2, 13001] loss: 0.58996
[  2, 13501] loss: 0.58506
[  2, 14001] loss: 0.63689
[  2, 14501] loss: 0.62597
[  2, 15001] loss: 0.61176
[  2, 15501] loss: 0.64106
[  2, 16001] loss: 0.66241
[  2, 16501] loss: 0.63608
[  2, 17001] loss: 0.66312
[  2, 17501] loss: 0.62809
[  2, 18001] loss: 0.64138
[  2, 18501] loss: 0.65608
[  2, 19001] loss: 0.65584
[  2, 19501] loss: 0.62684
[  2, 20001] loss: 0.59855
[  2, 20501] loss: 0.57834
[  2, 21001] loss: 0.60373
[  2, 21501] loss: 0.62686
[  2, 22001] loss: 0.65575
[  2, 22501] loss: 0.75291
[  2, 23001] loss: 0.78944
[  2, 23501] loss: 0.71537
[  2, 24001] loss: 0.70067
[  2, 24501] loss: 0.59786
Finished training
Accuracy on train: 0.80460
Accuracy on test: 0.56402
