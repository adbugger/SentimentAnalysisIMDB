{'word_context': 15, 'word_embed_size': 200, 'word_conv_units': 10, 'hidden_units': 5, 'dropout': True, 'batch_size': 500}
2482
train set done
test set done
[  1,     1] loss: 0.94648
[  1,   501] loss: 0.88683
[  1,  1001] loss: 0.86106
[  1,  1501] loss: 0.83386
[  1,  2001] loss: 0.83719
[  1,  2501] loss: 0.78831
[  1,  3001] loss: 0.85579
[  1,  3501] loss: 0.81388
[  1,  4001] loss: 0.78738
[  1,  4501] loss: 0.79212
[  1,  5001] loss: 0.77695
[  1,  5501] loss: 0.83626
[  1,  6001] loss: 0.80648
[  1,  6501] loss: 0.74278
[  1,  7001] loss: 0.77600
[  1,  7501] loss: 0.78117
[  1,  8001] loss: 0.75507
[  1,  8501] loss: 0.72998
[  1,  9001] loss: 0.75532
[  1,  9501] loss: 0.74314
[  1, 10001] loss: 0.73964
[  1, 10501] loss: 0.73712
[  1, 11001] loss: 0.73158
[  1, 11501] loss: 0.76906
[  1, 12001] loss: 0.71133
[  1, 12501] loss: 0.72873
[  1, 13001] loss: 0.70743
[  1, 13501] loss: 0.73997
[  1, 14001] loss: 0.70095
[  1, 14501] loss: 0.73711
[  1, 15001] loss: 0.74559
[  1, 15501] loss: 0.71476
[  1, 16001] loss: 0.72828
[  1, 16501] loss: 0.72002
[  1, 17001] loss: 0.71892
[  1, 17501] loss: 0.71361
[  1, 18001] loss: 0.72169
[  1, 18501] loss: 0.71200
[  1, 19001] loss: 0.74698
[  1, 19501] loss: 0.70075
[  1, 20001] loss: 0.69631
[  1, 20501] loss: 0.71394
[  1, 21001] loss: 0.71606
[  1, 21501] loss: 0.69734
[  1, 22001] loss: 0.72487
[  1, 22501] loss: 0.74993
[  1, 23001] loss: 0.72459
[  1, 23501] loss: 0.70606
[  1, 24001] loss: 0.71217
[  1, 24501] loss: 0.71298
[  2,     1] loss: 0.71576
[  2,   501] loss: 0.69783
[  2,  1001] loss: 0.69790
[  2,  1501] loss: 0.71930
[  2,  2001] loss: 0.71965
[  2,  2501] loss: 0.69393
[  2,  3001] loss: 0.69636
[  2,  3501] loss: 0.72212
[  2,  4001] loss: 0.68539
[  2,  4501] loss: 0.68304
[  2,  5001] loss: 0.69826
[  2,  5501] loss: 0.71363
[  2,  6001] loss: 0.69395
[  2,  6501] loss: 0.68605
[  2,  7001] loss: 0.68652
[  2,  7501] loss: 0.69797
[  2,  8001] loss: 0.70019
[  2,  8501] loss: 0.69208
[  2,  9001] loss: 0.72499
[  2,  9501] loss: 0.69446
[  2, 10001] loss: 0.68306
[  2, 10501] loss: 0.67655
[  2, 11001] loss: 0.70222
[  2, 11501] loss: 0.70721
[  2, 12001] loss: 0.66578
[  2, 12501] loss: 0.68637
[  2, 13001] loss: 0.68362
[  2, 13501] loss: 0.67313
[  2, 14001] loss: 0.68467
[  2, 14501] loss: 0.69533
[  2, 15001] loss: 0.69971
[  2, 15501] loss: 0.68619
[  2, 16001] loss: 0.67956
[  2, 16501] loss: 0.66486
[  2, 17001] loss: 0.68714
[  2, 17501] loss: 0.66838
[  2, 18001] loss: 0.65745
[  2, 18501] loss: 0.66691
[  2, 19001] loss: 0.66769
[  2, 19501] loss: 0.69125
[  2, 20001] loss: 0.68925
[  2, 20501] loss: 0.67180
[  2, 21001] loss: 0.66874
[  2, 21501] loss: 0.69069
[  2, 22001] loss: 0.69567
[  2, 22501] loss: 0.65471
[  2, 23001] loss: 0.69351
[  2, 23501] loss: 0.66307
[  2, 24001] loss: 0.67573
[  2, 24501] loss: 0.67534
Finished training
Accuracy on train: 0.62208
Accuracy on test: 0.54978
