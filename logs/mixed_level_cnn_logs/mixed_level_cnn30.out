{'word_context': 31, 'word_embed_size': 500, 'word_conv_units': 10, 'hidden_units': 5, 'dropout': False, 'batch_size': 500}
2482
train set done
test set done
[  1,     1] loss: 1.08897
[  1,   501] loss: 1.38817
[  1,  1001] loss: 1.26607
[  1,  1501] loss: 1.28237
[  1,  2001] loss: 1.04222
[  1,  2501] loss: 1.08590
[  1,  3001] loss: 1.03868
[  1,  3501] loss: 0.98572
[  1,  4001] loss: 0.83198
[  1,  4501] loss: 0.84978
[  1,  5001] loss: 0.86249
[  1,  5501] loss: 0.83633
[  1,  6001] loss: 0.79370
[  1,  6501] loss: 0.76195
[  1,  7001] loss: 0.80673
[  1,  7501] loss: 0.82911
[  1,  8001] loss: 0.80737
[  1,  8501] loss: 0.81402
[  1,  9001] loss: 0.74682
[  1,  9501] loss: 0.70674
[  1, 10001] loss: 0.73234
[  1, 10501] loss: 0.75468
[  1, 11001] loss: 0.78235
[  1, 11501] loss: 0.85872
[  1, 12001] loss: 0.84768
[  1, 12501] loss: 0.81402
[  1, 13001] loss: 0.74313
[  1, 13501] loss: 0.72465
[  1, 14001] loss: 0.71791
[  1, 14501] loss: 0.69620
[  1, 15001] loss: 0.69408
[  1, 15501] loss: 0.69927
[  1, 16001] loss: 0.73386
[  1, 16501] loss: 0.75768
[  1, 17001] loss: 0.77411
[  1, 17501] loss: 0.80762
[  1, 18001] loss: 0.75486
[  1, 18501] loss: 0.72192
[  1, 19001] loss: 0.80333
[  1, 19501] loss: 0.76531
[  1, 20001] loss: 0.76925
[  1, 20501] loss: 0.80570
[  1, 21001] loss: 0.79436
[  1, 21501] loss: 0.80269
[  1, 22001] loss: 0.74273
[  1, 22501] loss: 0.71664
[  1, 23001] loss: 0.73455
[  1, 23501] loss: 0.67726
[  1, 24001] loss: 0.71705
[  1, 24501] loss: 0.72056
[  2,     1] loss: 0.70757
[  2,   501] loss: 0.68352
[  2,  1001] loss: 0.74765
[  2,  1501] loss: 0.75886
[  2,  2001] loss: 0.76316
[  2,  2501] loss: 0.76932
[  2,  3001] loss: 0.78218
[  2,  3501] loss: 0.74129
[  2,  4001] loss: 0.70939
[  2,  4501] loss: 0.69209
[  2,  5001] loss: 0.70577
[  2,  5501] loss: 0.65997
[  2,  6001] loss: 0.67948
[  2,  6501] loss: 0.64853
[  2,  7001] loss: 0.67836
[  2,  7501] loss: 0.65113
[  2,  8001] loss: 0.66593
[  2,  8501] loss: 0.66469
[  2,  9001] loss: 0.65070
[  2,  9501] loss: 0.61928
[  2, 10001] loss: 0.65502
[  2, 10501] loss: 0.65489
[  2, 11001] loss: 0.69184
[  2, 11501] loss: 0.77608
[  2, 12001] loss: 0.80169
[  2, 12501] loss: 0.75549
[  2, 13001] loss: 0.66728
[  2, 13501] loss: 0.63057
[  2, 14001] loss: 0.64376
[  2, 14501] loss: 0.63144
[  2, 15001] loss: 0.63119
[  2, 15501] loss: 0.61036
[  2, 16001] loss: 0.65108
[  2, 16501] loss: 0.64570
[  2, 17001] loss: 0.68481
[  2, 17501] loss: 0.65347
[  2, 18001] loss: 0.63930
[  2, 18501] loss: 0.64265
[  2, 19001] loss: 0.68714
[  2, 19501] loss: 0.67768
[  2, 20001] loss: 0.68475
[  2, 20501] loss: 0.71789
[  2, 21001] loss: 0.71303
[  2, 21501] loss: 0.69895
[  2, 22001] loss: 0.62595
[  2, 22501] loss: 0.61484
[  2, 23001] loss: 0.61504
[  2, 23501] loss: 0.59732
[  2, 24001] loss: 0.63475
[  2, 24501] loss: 0.63631
Finished training
Accuracy on train: 0.67020
Accuracy on test: 0.54632
