{'word_context': 15, 'word_embed_size': 500, 'word_conv_units': 10, 'hidden_units': 5, 'dropout': True, 'batch_size': 500}
2482
train set done
test set done
[  1,     1] loss: 1.41897
[  1,   501] loss: 1.87324
[  1,  1001] loss: 1.22109
[  1,  1501] loss: 0.90583
[  1,  2001] loss: 0.96924
[  1,  2501] loss: 0.87087
[  1,  3001] loss: 0.90368
[  1,  3501] loss: 0.89554
[  1,  4001] loss: 0.86435
[  1,  4501] loss: 1.87861
[  1,  5001] loss: 1.01110
[  1,  5501] loss: 0.84005
[  1,  6001] loss: 0.84716
[  1,  6501] loss: 0.79705
[  1,  7001] loss: 0.88182
[  1,  7501] loss: 0.82909
[  1,  8001] loss: 0.91033
[  1,  8501] loss: 0.82723
[  1,  9001] loss: 0.85239
[  1,  9501] loss: 0.82615
[  1, 10001] loss: 0.85162
[  1, 10501] loss: 0.79402
[  1, 11001] loss: 0.86753
[  1, 11501] loss: 0.84595
[  1, 12001] loss: 0.85868
[  1, 12501] loss: 0.85067
[  1, 13001] loss: 0.83877
[  1, 13501] loss: 0.82033
[  1, 14001] loss: 0.81273
[  1, 14501] loss: 0.79073
[  1, 15001] loss: 0.82653
[  1, 15501] loss: 0.75626
[  1, 16001] loss: 1.30104
[  1, 16501] loss: 0.93096
[  1, 17001] loss: 0.81556
[  1, 17501] loss: 0.76083
[  1, 18001] loss: 0.81743
[  1, 18501] loss: 0.79314
[  1, 19001] loss: 0.76321
[  1, 19501] loss: 0.78726
[  1, 20001] loss: 0.83781
[  1, 20501] loss: 0.82982
[  1, 21001] loss: 0.79452
[  1, 21501] loss: 0.81268
[  1, 22001] loss: 0.76138
[  1, 22501] loss: 0.77954
[  1, 23001] loss: 0.79926
[  1, 23501] loss: 0.76855
[  1, 24001] loss: 0.76544
[  1, 24501] loss: 0.76275
[  2,     1] loss: 0.79839
[  2,   501] loss: 0.79767
[  2,  1001] loss: 0.77192
[  2,  1501] loss: 0.75003
[  2,  2001] loss: 0.78515
[  2,  2501] loss: 0.75247
[  2,  3001] loss: 0.76745
[  2,  3501] loss: 0.76312
[  2,  4001] loss: 0.74072
[  2,  4501] loss: 0.72874
[  2,  5001] loss: 0.73635
[  2,  5501] loss: 0.75423
[  2,  6001] loss: 0.74486
[  2,  6501] loss: 0.73035
[  2,  7001] loss: 0.77009
[  2,  7501] loss: 0.71515
[  2,  8001] loss: 0.72846
[  2,  8501] loss: 0.71371
[  2,  9001] loss: 0.73134
[  2,  9501] loss: 0.74754
[  2, 10001] loss: 0.74778
[  2, 10501] loss: 0.72993
[  2, 11001] loss: 0.75680
[  2, 11501] loss: 0.76834
[  2, 12001] loss: 0.70705
[  2, 12501] loss: 0.72382
[  2, 13001] loss: 0.76344
[  2, 13501] loss: 0.74434
[  2, 14001] loss: 0.73600
[  2, 14501] loss: 0.70631
[  2, 15001] loss: 0.72226
[  2, 15501] loss: 0.72048
[  2, 16001] loss: 0.69515
[  2, 16501] loss: 0.70652
[  2, 17001] loss: 0.72856
[  2, 17501] loss: 0.66410
[  2, 18001] loss: 0.71440
[  2, 18501] loss: 0.74484
[  2, 19001] loss: 0.72244
[  2, 19501] loss: 0.69330
[  2, 20001] loss: 0.69818
[  2, 20501] loss: 0.68313
[  2, 21001] loss: 0.67966
[  2, 21501] loss: 0.70037
[  2, 22001] loss: 0.69749
[  2, 22501] loss: 0.70952
[  2, 23001] loss: 0.69756
[  2, 23501] loss: 0.71294
[  2, 24001] loss: 0.72640
[  2, 24501] loss: 0.66977
Finished training
Accuracy on train: 0.61984
Accuracy on test: 0.54370
