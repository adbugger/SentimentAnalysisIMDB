{'word_context': 101, 'word_embed_size': 500, 'word_conv_units': 10, 'hidden_units': 5, 'dropout': True, 'batch_size': 500}
2482
train set done
test set done
[  1,     1] loss: 1.28023
[  1,   501] loss: 9.93182
[  1,  1001] loss: 2.72566
[  1,  1501] loss: 2.00611
[  1,  2001] loss: 15.88552
[  1,  2501] loss: 1.89472
[  1,  3001] loss: 1.67602
[  1,  3501] loss: 1.73517
[  1,  4001] loss: 2.20205
[  1,  4501] loss: 1.98032
[  1,  5001] loss: 1.66620
[  1,  5501] loss: 1.31587
[  1,  6001] loss: 1.50378
[  1,  6501] loss: 1.34433
[  1,  7001] loss: 1.67002
[  1,  7501] loss: 1.78533
[  1,  8001] loss: 1.49844
[  1,  8501] loss: 1.39371
[  1,  9001] loss: 1.40537
[  1,  9501] loss: 1.35779
[  1, 10001] loss: 1.35930
[  1, 10501] loss: 1.38176
[  1, 11001] loss: 1.49401
[  1, 11501] loss: 1.48662
[  1, 12001] loss: 1.19318
[  1, 12501] loss: 1.22271
[  1, 13001] loss: 1.45273
[  1, 13501] loss: 1.06972
[  1, 14001] loss: 1.02558
[  1, 14501] loss: 1.10376
[  1, 15001] loss: 0.98943
[  1, 15501] loss: 1.10174
[  1, 16001] loss: 1.14094
[  1, 16501] loss: 1.06877
[  1, 17001] loss: 0.98587
[  1, 17501] loss: 0.86183
[  1, 18001] loss: 3.92592
[  1, 18501] loss: 1.43963
[  1, 19001] loss: 0.97859
[  1, 19501] loss: 0.83956
[  1, 20001] loss: 0.98034
[  1, 20501] loss: 0.77646
[  1, 21001] loss: 1.02434
[  1, 21501] loss: 0.84185
[  1, 22001] loss: 1.00608
[  1, 22501] loss: 0.89533
[  1, 23001] loss: 0.95235
[  1, 23501] loss: 0.93983
[  1, 24001] loss: 1.00369
[  1, 24501] loss: 1.12087
[  2,     1] loss: 1.13811
[  2,   501] loss: 0.97637
[  2,  1001] loss: 1.10160
[  2,  1501] loss: 0.84349
[  2,  2001] loss: 0.90432
[  2,  2501] loss: 0.87718
[  2,  3001] loss: 0.84934
[  2,  3501] loss: 0.98859
[  2,  4001] loss: 1.11652
[  2,  4501] loss: 0.80092
[  2,  5001] loss: 0.94021
[  2,  5501] loss: 0.78101
[  2,  6001] loss: 1.00253
[  2,  6501] loss: 0.94623
[  2,  7001] loss: 0.88090
[  2,  7501] loss: 0.76663
[  2,  8001] loss: 0.84536
[  2,  8501] loss: 0.77131
[  2,  9001] loss: 0.80655
[  2,  9501] loss: 0.76970
[  2, 10001] loss: 0.81618
[  2, 10501] loss: 0.78972
[  2, 11001] loss: 0.81487
[  2, 11501] loss: 0.75797
[  2, 12001] loss: 0.80779
[  2, 12501] loss: 0.75322
[  2, 13001] loss: 0.77820
[  2, 13501] loss: 0.66604
[  2, 14001] loss: 0.70579
[  2, 14501] loss: 0.71902
[  2, 15001] loss: 0.75303
[  2, 15501] loss: 0.72156
[  2, 16001] loss: 0.77753
[  2, 16501] loss: 0.70500
[  2, 17001] loss: 0.82407
[  2, 17501] loss: 0.76465
[  2, 18001] loss: 0.80769
[  2, 18501] loss: 0.78533
[  2, 19001] loss: 0.82452
[  2, 19501] loss: 0.75797
[  2, 20001] loss: 0.77231
[  2, 20501] loss: 0.73189
[  2, 21001] loss: 0.73372
[  2, 21501] loss: 0.67938
[  2, 22001] loss: 0.65577
[  2, 22501] loss: 0.70114
[  2, 23001] loss: 0.63575
[  2, 23501] loss: 0.69953
[  2, 24001] loss: 0.66893
[  2, 24501] loss: 0.70869
Finished training
Accuracy on train: 0.69356
Accuracy on test: 0.56234
