{'word_context': 15, 'word_embed_size': 30, 'word_conv_units': 10, 'hidden_units': 5, 'dropout': True, 'batch_size': 500}
2482
train set done
test set done
[  1,     1] loss: 1.32557
[  1,   501] loss: 1.04446
[  1,  1001] loss: 1.01528
[  1,  1501] loss: 0.86950
[  1,  2001] loss: 0.87434
[  1,  2501] loss: 0.83238
[  1,  3001] loss: 0.76853
[  1,  3501] loss: 0.76322
[  1,  4001] loss: 0.74765
[  1,  4501] loss: 0.75522
[  1,  5001] loss: 0.76495
[  1,  5501] loss: 0.75540
[  1,  6001] loss: 0.76502
[  1,  6501] loss: 0.76138
[  1,  7001] loss: 0.76972
[  1,  7501] loss: 0.70962
[  1,  8001] loss: 0.75948
[  1,  8501] loss: 0.74968
[  1,  9001] loss: 0.70690
[  1,  9501] loss: 0.74853
[  1, 10001] loss: 0.71901
[  1, 10501] loss: 0.75166
[  1, 11001] loss: 0.74007
[  1, 11501] loss: 0.74564
[  1, 12001] loss: 0.71701
[  1, 12501] loss: 0.71859
[  1, 13001] loss: 0.73382
[  1, 13501] loss: 0.73357
[  1, 14001] loss: 0.72460
[  1, 14501] loss: 0.70861
[  1, 15001] loss: 0.70616
[  1, 15501] loss: 0.71034
[  1, 16001] loss: 0.72169
[  1, 16501] loss: 0.70934
[  1, 17001] loss: 0.70863
[  1, 17501] loss: 0.69722
[  1, 18001] loss: 0.71536
[  1, 18501] loss: 0.70352
[  1, 19001] loss: 0.71875
[  1, 19501] loss: 0.72227
[  1, 20001] loss: 0.70297
[  1, 20501] loss: 0.69069
[  1, 21001] loss: 0.69430
[  1, 21501] loss: 0.69017
[  1, 22001] loss: 0.70062
[  1, 22501] loss: 0.70360
[  1, 23001] loss: 0.69194
[  1, 23501] loss: 0.70466
[  1, 24001] loss: 0.69771
[  1, 24501] loss: 0.68566
[  2,     1] loss: 0.68591
[  2,   501] loss: 0.69858
[  2,  1001] loss: 0.70409
[  2,  1501] loss: 0.68079
[  2,  2001] loss: 0.70188
[  2,  2501] loss: 0.70210
[  2,  3001] loss: 0.69418
[  2,  3501] loss: 0.69787
[  2,  4001] loss: 0.67293
[  2,  4501] loss: 0.70264
[  2,  5001] loss: 0.70102
[  2,  5501] loss: 0.70237
[  2,  6001] loss: 0.68727
[  2,  6501] loss: 0.69021
[  2,  7001] loss: 0.68505
[  2,  7501] loss: 0.67718
[  2,  8001] loss: 0.69183
[  2,  8501] loss: 0.70024
[  2,  9001] loss: 0.68863
[  2,  9501] loss: 0.70124
[  2, 10001] loss: 0.69834
[  2, 10501] loss: 0.69777
[  2, 11001] loss: 0.69959
[  2, 11501] loss: 0.69068
[  2, 12001] loss: 0.69070
[  2, 12501] loss: 0.68655
[  2, 13001] loss: 0.68554
[  2, 13501] loss: 0.70146
[  2, 14001] loss: 0.69269
[  2, 14501] loss: 0.69799
[  2, 15001] loss: 0.68123
[  2, 15501] loss: 0.69263
[  2, 16001] loss: 0.69708
[  2, 16501] loss: 0.69513
[  2, 17001] loss: 0.69573
[  2, 17501] loss: 0.69472
[  2, 18001] loss: 0.69475
[  2, 18501] loss: 0.69427
[  2, 19001] loss: 0.68863
[  2, 19501] loss: 0.70342
[  2, 20001] loss: 0.68336
[  2, 20501] loss: 0.69195
[  2, 21001] loss: 0.69574
[  2, 21501] loss: 0.68934
[  2, 22001] loss: 0.67520
[  2, 22501] loss: 0.67163
[  2, 23001] loss: 0.69238
[  2, 23501] loss: 0.67993
[  2, 24001] loss: 0.68586
[  2, 24501] loss: 0.69061
[  3,     1] loss: 0.68729
[  3,   501] loss: 0.68825
[  3,  1001] loss: 0.67947
[  3,  1501] loss: 0.70000
[  3,  2001] loss: 0.68265
[  3,  2501] loss: 0.68890
[  3,  3001] loss: 0.68994
[  3,  3501] loss: 0.68541
[  3,  4001] loss: 0.68674
[  3,  4501] loss: 0.69428
[  3,  5001] loss: 0.69337
[  3,  5501] loss: 0.69483
[  3,  6001] loss: 0.68694
[  3,  6501] loss: 0.68870
[  3,  7001] loss: 0.68511
[  3,  7501] loss: 0.68471
[  3,  8001] loss: 0.68472
[  3,  8501] loss: 0.69494
[  3,  9001] loss: 0.69205
[  3,  9501] loss: 0.69089
[  3, 10001] loss: 0.69480
[  3, 10501] loss: 0.68342
[  3, 11001] loss: 0.68616
[  3, 11501] loss: 0.68287
[  3, 12001] loss: 0.69021
[  3, 12501] loss: 0.68493
[  3, 13001] loss: 0.68999
[  3, 13501] loss: 0.70147
[  3, 14001] loss: 0.67776
[  3, 14501] loss: 0.67898
[  3, 15001] loss: 0.69386
[  3, 15501] loss: 0.68000
[  3, 16001] loss: 0.69178
[  3, 16501] loss: 0.68396
[  3, 17001] loss: 0.69523
[  3, 17501] loss: 0.68739
[  3, 18001] loss: 0.68776
[  3, 18501] loss: 0.69384
[  3, 19001] loss: 0.68946
[  3, 19501] loss: 0.68976
[  3, 20001] loss: 0.68578
[  3, 20501] loss: 0.68870
[  3, 21001] loss: 0.68977
[  3, 21501] loss: 0.68535
[  3, 22001] loss: 0.67245
[  3, 22501] loss: 0.68190
[  3, 23001] loss: 0.68805
[  3, 23501] loss: 0.68401
[  3, 24001] loss: 0.67908
[  3, 24501] loss: 0.68472
[  4,     1] loss: 0.67763
[  4,   501] loss: 0.68010
[  4,  1001] loss: 0.67507
[  4,  1501] loss: 0.69103
[  4,  2001] loss: 0.68353
[  4,  2501] loss: 0.68059
[  4,  3001] loss: 0.69391
[  4,  3501] loss: 0.67659
[  4,  4001] loss: 0.67606
[  4,  4501] loss: 0.67914
[  4,  5001] loss: 0.68509
[  4,  5501] loss: 0.68226
[  4,  6001] loss: 0.67952
[  4,  6501] loss: 0.67260
[  4,  7001] loss: 0.68973
[  4,  7501] loss: 0.67935
[  4,  8001] loss: 0.67986
[  4,  8501] loss: 0.69149
[  4,  9001] loss: 0.68723
[  4,  9501] loss: 0.69321
[  4, 10001] loss: 0.67706
[  4, 10501] loss: 0.67882
[  4, 11001] loss: 0.68329
[  4, 11501] loss: 0.67726
[  4, 12001] loss: 0.69074
[  4, 12501] loss: 0.68305
[  4, 13001] loss: 0.68945
[  4, 13501] loss: 0.68758
[  4, 14001] loss: 0.67876
[  4, 14501] loss: 0.68517
[  4, 15001] loss: 0.67555
[  4, 15501] loss: 0.67921
[  4, 16001] loss: 0.67883
[  4, 16501] loss: 0.68291
[  4, 17001] loss: 0.68505
[  4, 17501] loss: 0.67480
[  4, 18001] loss: 0.68558
[  4, 18501] loss: 0.67599
[  4, 19001] loss: 0.67814
[  4, 19501] loss: 0.67983
[  4, 20001] loss: 0.67773
[  4, 20501] loss: 0.68139
[  4, 21001] loss: 0.67661
[  4, 21501] loss: 0.68434
[  4, 22001] loss: 0.67859
[  4, 22501] loss: 0.66625
[  4, 23001] loss: 0.68648
[  4, 23501] loss: 0.67435
[  4, 24001] loss: 0.68014
[  4, 24501] loss: 0.68870
[  5,     1] loss: 0.67068
[  5,   501] loss: 0.69050
[  5,  1001] loss: 0.68575
[  5,  1501] loss: 0.67689
[  5,  2001] loss: 0.68048
[  5,  2501] loss: 0.68743
[  5,  3001] loss: 0.68886
[  5,  3501] loss: 0.66973
[  5,  4001] loss: 0.66699
[  5,  4501] loss: 0.68025
[  5,  5001] loss: 0.68170
[  5,  5501] loss: 0.69019
[  5,  6001] loss: 0.67606
[  5,  6501] loss: 0.67291
[  5,  7001] loss: 0.67386
[  5,  7501] loss: 0.67672
[  5,  8001] loss: 0.68460
[  5,  8501] loss: 0.69344
[  5,  9001] loss: 0.67635
[  5,  9501] loss: 0.67987
[  5, 10001] loss: 0.68698
[  5, 10501] loss: 0.69125
[  5, 11001] loss: 0.67995
[  5, 11501] loss: 0.67473
[  5, 12001] loss: 0.68637
[  5, 12501] loss: 0.68064
[  5, 13001] loss: 0.67608
[  5, 13501] loss: 0.68650
[  5, 14001] loss: 0.68487
[  5, 14501] loss: 0.68299
[  5, 15001] loss: 0.68331
[  5, 15501] loss: 0.68296
[  5, 16001] loss: 0.67660
[  5, 16501] loss: 0.67938
[  5, 17001] loss: 0.69353
[  5, 17501] loss: 0.68259
[  5, 18001] loss: 0.67474
[  5, 18501] loss: 0.68174
[  5, 19001] loss: 0.68702
[  5, 19501] loss: 0.67843
[  5, 20001] loss: 0.67052
[  5, 20501] loss: 0.68926
[  5, 21001] loss: 0.68827
[  5, 21501] loss: 0.67916
[  5, 22001] loss: 0.67894
[  5, 22501] loss: 0.67377
[  5, 23001] loss: 0.67675
[  5, 23501] loss: 0.67238
[  5, 24001] loss: 0.67740
[  5, 24501] loss: 0.68564
[  6,     1] loss: 0.66673
[  6,   501] loss: 0.69214
[  6,  1001] loss: 0.67259
[  6,  1501] loss: 0.66988
[  6,  2001] loss: 0.68153
[  6,  2501] loss: 0.68119
[  6,  3001] loss: 0.68482
[  6,  3501] loss: 0.67050
[  6,  4001] loss: 0.67990
[  6,  4501] loss: 0.67245
[  6,  5001] loss: 0.68229
[  6,  5501] loss: 0.68384
[  6,  6001] loss: 0.67886
[  6,  6501] loss: 0.67039
[  6,  7001] loss: 0.67327
[  6,  7501] loss: 0.68026
[  6,  8001] loss: 0.69393
[  6,  8501] loss: 0.68826
[  6,  9001] loss: 0.67925
[  6,  9501] loss: 0.68303
[  6, 10001] loss: 0.68572
[  6, 10501] loss: 0.67715
[  6, 11001] loss: 0.67936
[  6, 11501] loss: 0.67382
[  6, 12001] loss: 0.68509
[  6, 12501] loss: 0.67461
[  6, 13001] loss: 0.68747
[  6, 13501] loss: 0.69213
[  6, 14001] loss: 0.66938
[  6, 14501] loss: 0.67190
[  6, 15001] loss: 0.67658
[  6, 15501] loss: 0.67187
[  6, 16001] loss: 0.67384
[  6, 16501] loss: 0.68703
[  6, 17001] loss: 0.68390
[  6, 17501] loss: 0.68463
[  6, 18001] loss: 0.67033
[  6, 18501] loss: 0.67189
[  6, 19001] loss: 0.67356
[  6, 19501] loss: 0.68018
[  6, 20001] loss: 0.67253
[  6, 20501] loss: 0.67760
[  6, 21001] loss: 0.67831
[  6, 21501] loss: 0.68064
[  6, 22001] loss: 0.66833
[  6, 22501] loss: 0.66512
[  6, 23001] loss: 0.67910
[  6, 23501] loss: 0.66351
[  6, 24001] loss: 0.67687
[  6, 24501] loss: 0.68298
[  7,     1] loss: 0.66675
[  7,   501] loss: 0.67306
[  7,  1001] loss: 0.68320
[  7,  1501] loss: 0.67053
[  7,  2001] loss: 0.67831
[  7,  2501] loss: 0.68393
[  7,  3001] loss: 0.68212
[  7,  3501] loss: 0.65291
[  7,  4001] loss: 0.66544
[  7,  4501] loss: 0.66830
[  7,  5001] loss: 0.66268
[  7,  5501] loss: 0.67200
[  7,  6001] loss: 0.67105
[  7,  6501] loss: 0.66711
[  7,  7001] loss: 0.66488
[  7,  7501] loss: 0.66702
[  7,  8001] loss: 0.66959
[  7,  8501] loss: 0.67286
[  7,  9001] loss: 0.67541
[  7,  9501] loss: 0.68145
[  7, 10001] loss: 0.67027
[  7, 10501] loss: 0.68261
[  7, 11001] loss: 0.68656
[  7, 11501] loss: 0.68544
[  7, 12001] loss: 0.67953
[  7, 12501] loss: 0.66561
[  7, 13001] loss: 0.67067
[  7, 13501] loss: 0.67789
[  7, 14001] loss: 0.67360
[  7, 14501] loss: 0.69054
[  7, 15001] loss: 0.66610
[  7, 15501] loss: 0.66332
[  7, 16001] loss: 0.68931
[  7, 16501] loss: 0.67423
[  7, 17001] loss: 0.66694
[  7, 17501] loss: 0.67804
[  7, 18001] loss: 0.65577
[  7, 18501] loss: 0.67643
[  7, 19001] loss: 0.67908
[  7, 19501] loss: 0.68785
[  7, 20001] loss: 0.67323
[  7, 20501] loss: 0.68236
[  7, 21001] loss: 0.68432
[  7, 21501] loss: 0.67456
[  7, 22001] loss: 0.66558
[  7, 22501] loss: 0.67979
[  7, 23001] loss: 0.67113
[  7, 23501] loss: 0.66792
[  7, 24001] loss: 0.66905
[  7, 24501] loss: 0.66436
Finished training
Accuracy on train: 0.58948
Accuracy on test: 0.53164
