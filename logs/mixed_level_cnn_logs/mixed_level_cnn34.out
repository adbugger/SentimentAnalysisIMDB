{'word_context': 31, 'word_embed_size': 200, 'word_conv_units': 100, 'hidden_units': 5, 'dropout': False, 'batch_size': 500}
2482
train set done
test set done
[  1,     1] loss: 1.14649
[  1,   501] loss: 6.63989
[  1,  1001] loss: 1.11087
[  1,  1501] loss: 2.57956
[  1,  2001] loss: 1.28507
[  1,  2501] loss: 1.87790
[  1,  3001] loss: 1.46241
[  1,  3501] loss: 1.55796
[  1,  4001] loss: 1.09719
[  1,  4501] loss: 1.17660
[  1,  5001] loss: 1.06879
[  1,  5501] loss: 1.03660
[  1,  6001] loss: 0.96531
[  1,  6501] loss: 0.99554
[  1,  7001] loss: 0.92258
[  1,  7501] loss: 0.98785
[  1,  8001] loss: 1.06990
[  1,  8501] loss: 1.05617
[  1,  9001] loss: 0.83878
[  1,  9501] loss: 0.79785
[  1, 10001] loss: 0.77336
[  1, 10501] loss: 0.81302
[  1, 11001] loss: 0.84250
[  1, 11501] loss: 0.84938
[  1, 12001] loss: 0.83221
[  1, 12501] loss: 0.81876
[  1, 13001] loss: 0.73691
[  1, 13501] loss: 0.72663
[  1, 14001] loss: 0.77000
[  1, 14501] loss: 0.76522
[  1, 15001] loss: 0.75065
[  1, 15501] loss: 0.73200
[  1, 16001] loss: 0.70677
[  1, 16501] loss: 0.70966
[  1, 17001] loss: 0.74388
[  1, 17501] loss: 0.79642
[  1, 18001] loss: 0.90048
[  1, 18501] loss: 0.92296
[  1, 19001] loss: 0.86263
[  1, 19501] loss: 0.96438
[  1, 20001] loss: 0.92522
[  1, 20501] loss: 0.86805
[  1, 21001] loss: 0.83429
[  1, 21501] loss: 0.74795
[  1, 22001] loss: 0.71151
[  1, 22501] loss: 0.71660
[  1, 23001] loss: 0.70667
[  1, 23501] loss: 0.72263
[  1, 24001] loss: 0.78326
[  1, 24501] loss: 0.78906
[  2,     1] loss: 0.71584
[  2,   501] loss: 0.71186
[  2,  1001] loss: 0.71740
[  2,  1501] loss: 0.69819
[  2,  2001] loss: 0.68612
[  2,  2501] loss: 0.64906
[  2,  3001] loss: 0.66341
[  2,  3501] loss: 0.66096
[  2,  4001] loss: 0.66263
[  2,  4501] loss: 0.65281
[  2,  5001] loss: 0.65503
[  2,  5501] loss: 0.62759
[  2,  6001] loss: 0.67950
[  2,  6501] loss: 0.64562
[  2,  7001] loss: 0.67240
[  2,  7501] loss: 0.69629
[  2,  8001] loss: 0.79968
[  2,  8501] loss: 0.83695
[  2,  9001] loss: 0.70185
[  2,  9501] loss: 0.65964
[  2, 10001] loss: 0.65013
[  2, 10501] loss: 0.65805
[  2, 11001] loss: 0.68683
[  2, 11501] loss: 0.64186
[  2, 12001] loss: 0.66261
[  2, 12501] loss: 0.64305
[  2, 13001] loss: 0.58633
[  2, 13501] loss: 0.56905
[  2, 14001] loss: 0.63238
[  2, 14501] loss: 0.60839
[  2, 15001] loss: 0.63707
[  2, 15501] loss: 0.58501
[  2, 16001] loss: 0.56394
[  2, 16501] loss: 0.57622
[  2, 17001] loss: 0.60162
[  2, 17501] loss: 0.62526
[  2, 18001] loss: 0.71454
[  2, 18501] loss: 0.76649
[  2, 19001] loss: 0.75468
[  2, 19501] loss: 0.86721
[  2, 20001] loss: 0.84243
[  2, 20501] loss: 0.77057
[  2, 21001] loss: 0.71339
[  2, 21501] loss: 0.61950
[  2, 22001] loss: 0.58074
[  2, 22501] loss: 0.59173
[  2, 23001] loss: 0.57011
[  2, 23501] loss: 0.56235
[  2, 24001] loss: 0.59577
[  2, 24501] loss: 0.59267
Finished training
Accuracy on train: 0.74304
Accuracy on test: 0.55334
