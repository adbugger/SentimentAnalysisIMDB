{'word_context': 31, 'word_embed_size': 200, 'word_conv_units': 10, 'hidden_units': 5, 'dropout': True, 'batch_size': 500}
2482
train set done
test set done
[  1,     1] loss: 0.78585
[  1,   501] loss: 0.98996
[  1,  1001] loss: 0.81661
[  1,  1501] loss: 0.73785
[  1,  2001] loss: 0.72482
[  1,  2501] loss: 0.75640
[  1,  3001] loss: 0.72491
[  1,  3501] loss: 0.72183
[  1,  4001] loss: 0.73438
[  1,  4501] loss: 0.71934
[  1,  5001] loss: 0.74791
[  1,  5501] loss: 0.75012
[  1,  6001] loss: 0.71113
[  1,  6501] loss: 0.72209
[  1,  7001] loss: 0.70384
[  1,  7501] loss: 0.72791
[  1,  8001] loss: 0.68648
[  1,  8501] loss: 0.70316
[  1,  9001] loss: 0.72722
[  1,  9501] loss: 0.71846
[  1, 10001] loss: 0.73132
[  1, 10501] loss: 0.70194
[  1, 11001] loss: 0.70986
[  1, 11501] loss: 0.72416
[  1, 12001] loss: 0.73788
[  1, 12501] loss: 0.71848
[  1, 13001] loss: 0.70584
[  1, 13501] loss: 0.73688
[  1, 14001] loss: 0.71648
[  1, 14501] loss: 0.71084
[  1, 15001] loss: 0.71821
[  1, 15501] loss: 0.74008
[  1, 16001] loss: 0.71607
[  1, 16501] loss: 0.69780
[  1, 17001] loss: 0.73292
[  1, 17501] loss: 0.68156
[  1, 18001] loss: 0.69961
[  1, 18501] loss: 0.71491
[  1, 19001] loss: 0.70959
[  1, 19501] loss: 0.71364
[  1, 20001] loss: 0.71216
[  1, 20501] loss: 0.69989
[  1, 21001] loss: 0.70299
[  1, 21501] loss: 0.70809
[  1, 22001] loss: 0.71753
[  1, 22501] loss: 0.71509
[  1, 23001] loss: 0.70157
[  1, 23501] loss: 0.71230
[  1, 24001] loss: 0.70637
[  1, 24501] loss: 0.71196
[  2,     1] loss: 0.70326
[  2,   501] loss: 0.70505
[  2,  1001] loss: 0.68120
[  2,  1501] loss: 0.69368
[  2,  2001] loss: 0.69162
[  2,  2501] loss: 0.69987
[  2,  3001] loss: 0.69343
[  2,  3501] loss: 0.72098
[  2,  4001] loss: 0.69608
[  2,  4501] loss: 0.69871
[  2,  5001] loss: 0.69716
[  2,  5501] loss: 0.72032
[  2,  6001] loss: 0.70610
[  2,  6501] loss: 0.68301
[  2,  7001] loss: 0.69364
[  2,  7501] loss: 0.68429
[  2,  8001] loss: 0.68866
[  2,  8501] loss: 0.67425
[  2,  9001] loss: 0.66415
[  2,  9501] loss: 0.68017
[  2, 10001] loss: 0.69251
[  2, 10501] loss: 0.68452
[  2, 11001] loss: 0.68561
[  2, 11501] loss: 0.66418
[  2, 12001] loss: 0.69651
[  2, 12501] loss: 0.67099
[  2, 13001] loss: 0.66826
[  2, 13501] loss: 0.67576
[  2, 14001] loss: 0.68627
[  2, 14501] loss: 0.67926
[  2, 15001] loss: 0.68345
[  2, 15501] loss: 0.67410
[  2, 16001] loss: 0.66933
[  2, 16501] loss: 0.66507
[  2, 17001] loss: 0.67607
[  2, 17501] loss: 0.67930
[  2, 18001] loss: 0.67518
[  2, 18501] loss: 0.66473
[  2, 19001] loss: 0.65828
[  2, 19501] loss: 0.66115
[  2, 20001] loss: 0.67088
[  2, 20501] loss: 0.65065
[  2, 21001] loss: 0.68014
[  2, 21501] loss: 0.66260
[  2, 22001] loss: 0.67769
[  2, 22501] loss: 0.64146
[  2, 23001] loss: 0.65660
[  2, 23501] loss: 0.66594
[  2, 24001] loss: 0.67402
[  2, 24501] loss: 0.67518
Finished training
Accuracy on train: 0.64064
Accuracy on test: 0.55178
