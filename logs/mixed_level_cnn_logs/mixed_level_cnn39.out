{'word_context': 31, 'word_embed_size': 200, 'word_conv_units': 10, 'hidden_units': 500, 'dropout': False, 'batch_size': 500}
2482
train set done
test set done
[  1,     1] loss: 0.70162
[  1,   501] loss: 2.24953
[  1,  1001] loss: 1.14772
[  1,  1501] loss: 0.90482
[  1,  2001] loss: 0.77332
[  1,  2501] loss: 0.73355
[  1,  3001] loss: 0.74316
[  1,  3501] loss: 0.76563
[  1,  4001] loss: 0.81764
[  1,  4501] loss: 0.84145
[  1,  5001] loss: 0.80267
[  1,  5501] loss: 0.81462
[  1,  6001] loss: 0.78775
[  1,  6501] loss: 0.81536
[  1,  7001] loss: 0.81480
[  1,  7501] loss: 0.76857
[  1,  8001] loss: 0.76000
[  1,  8501] loss: 0.74608
[  1,  9001] loss: 0.73581
[  1,  9501] loss: 0.72228
[  1, 10001] loss: 0.76240
[  1, 10501] loss: 0.77748
[  1, 11001] loss: 0.79291
[  1, 11501] loss: 0.72966
[  1, 12001] loss: 0.69981
[  1, 12501] loss: 0.70606
[  1, 13001] loss: 0.68649
[  1, 13501] loss: 0.68616
[  1, 14001] loss: 0.75249
[  1, 14501] loss: 0.87784
[  1, 15001] loss: 0.95832
[  1, 15501] loss: 0.89416
[  1, 16001] loss: 0.89750
[  1, 16501] loss: 0.76230
[  1, 17001] loss: 0.72946
[  1, 17501] loss: 0.69698
[  1, 18001] loss: 0.65743
[  1, 18501] loss: 0.68326
[  1, 19001] loss: 0.73460
[  1, 19501] loss: 0.72389
[  1, 20001] loss: 0.75770
[  1, 20501] loss: 0.80340
[  1, 21001] loss: 0.81358
[  1, 21501] loss: 0.80692
[  1, 22001] loss: 0.81056
[  1, 22501] loss: 0.76101
[  1, 23001] loss: 0.74379
[  1, 23501] loss: 0.79523
[  1, 24001] loss: 0.81339
[  1, 24501] loss: 0.80573
[  2,     1] loss: 0.68223
[  2,   501] loss: 0.69528
[  2,  1001] loss: 0.69081
[  2,  1501] loss: 0.63404
[  2,  2001] loss: 0.64797
[  2,  2501] loss: 0.64027
[  2,  3001] loss: 0.62597
[  2,  3501] loss: 0.61834
[  2,  4001] loss: 0.64199
[  2,  4501] loss: 0.64672
[  2,  5001] loss: 0.61675
[  2,  5501] loss: 0.63376
[  2,  6001] loss: 0.62836
[  2,  6501] loss: 0.61824
[  2,  7001] loss: 0.62600
[  2,  7501] loss: 0.62207
[  2,  8001] loss: 0.62873
[  2,  8501] loss: 0.62174
[  2,  9001] loss: 0.61760
[  2,  9501] loss: 0.65093
[  2, 10001] loss: 0.72789
[  2, 10501] loss: 0.81520
[  2, 11001] loss: 0.79637
[  2, 11501] loss: 0.68879
[  2, 12001] loss: 0.64805
[  2, 12501] loss: 0.65744
[  2, 13001] loss: 0.61973
[  2, 13501] loss: 0.64571
[  2, 14001] loss: 0.72561
[  2, 14501] loss: 0.77845
[  2, 15001] loss: 0.79270
[  2, 15501] loss: 0.72313
[  2, 16001] loss: 0.77689
[  2, 16501] loss: 0.67166
[  2, 17001] loss: 0.63324
[  2, 17501] loss: 0.62571
[  2, 18001] loss: 0.55322
[  2, 18501] loss: 0.60152
[  2, 19001] loss: 0.65649
[  2, 19501] loss: 0.62124
[  2, 20001] loss: 0.64291
[  2, 20501] loss: 0.67967
[  2, 21001] loss: 0.67192
[  2, 21501] loss: 0.67980
[  2, 22001] loss: 0.71907
[  2, 22501] loss: 0.69996
[  2, 23001] loss: 0.66486
[  2, 23501] loss: 0.71751
[  2, 24001] loss: 0.73276
[  2, 24501] loss: 0.70371
Finished training
Accuracy on train: 0.62480
Accuracy on test: 0.53322
