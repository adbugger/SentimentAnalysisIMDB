{'word_context': 31, 'word_embed_size': 200, 'word_conv_units': 10, 'hidden_units': 5, 'dropout': True, 'batch_size': 500}
2482
train set done
test set done
[  1,     1] loss: 1.09864
[  1,   501] loss: 2.63669
[  1,  1001] loss: 1.12695
[  1,  1501] loss: 0.80785
[  1,  2001] loss: 0.81286
[  1,  2501] loss: 0.78381
[  1,  3001] loss: 0.80583
[  1,  3501] loss: 0.79794
[  1,  4001] loss: 0.75441
[  1,  4501] loss: 0.77488
[  1,  5001] loss: 0.76122
[  1,  5501] loss: 0.73484
[  1,  6001] loss: 0.77416
[  1,  6501] loss: 0.78066
[  1,  7001] loss: 0.73396
[  1,  7501] loss: 0.75986
[  1,  8001] loss: 0.75944
[  1,  8501] loss: 0.77381
[  1,  9001] loss: 0.70986
[  1,  9501] loss: 0.71785
[  1, 10001] loss: 0.73176
[  1, 10501] loss: 0.74128
[  1, 11001] loss: 0.72411
[  1, 11501] loss: 0.73786
[  1, 12001] loss: 0.72882
[  1, 12501] loss: 0.74852
[  1, 13001] loss: 0.72802
[  1, 13501] loss: 0.73094
[  1, 14001] loss: 0.71782
[  1, 14501] loss: 0.73250
[  1, 15001] loss: 0.74714
[  1, 15501] loss: 0.69447
[  1, 16001] loss: 0.75463
[  1, 16501] loss: 0.76124
[  1, 17001] loss: 0.74931
[  1, 17501] loss: 0.73750
[  1, 18001] loss: 0.71605
[  1, 18501] loss: 0.71037
[  1, 19001] loss: 0.69320
[  1, 19501] loss: 0.71217
[  1, 20001] loss: 0.71098
[  1, 20501] loss: 0.72472
[  1, 21001] loss: 0.72616
[  1, 21501] loss: 0.72829
[  1, 22001] loss: 0.72403
[  1, 22501] loss: 0.74366
[  1, 23001] loss: 0.73760
[  1, 23501] loss: 0.74340
[  1, 24001] loss: 0.73740
[  1, 24501] loss: 0.69378
[  2,     1] loss: 0.73979
[  2,   501] loss: 0.71402
[  2,  1001] loss: 0.68121
[  2,  1501] loss: 0.71406
[  2,  2001] loss: 0.70924
[  2,  2501] loss: 0.71362
[  2,  3001] loss: 0.71609
[  2,  3501] loss: 0.75193
[  2,  4001] loss: 0.71476
[  2,  4501] loss: 0.70148
[  2,  5001] loss: 0.71883
[  2,  5501] loss: 0.70701
[  2,  6001] loss: 0.72567
[  2,  6501] loss: 0.71977
[  2,  7001] loss: 0.71089
[  2,  7501] loss: 0.71055
[  2,  8001] loss: 0.72244
[  2,  8501] loss: 0.71934
[  2,  9001] loss: 0.68001
[  2,  9501] loss: 0.72850
[  2, 10001] loss: 0.70820
[  2, 10501] loss: 0.70515
[  2, 11001] loss: 0.71566
[  2, 11501] loss: 0.68417
[  2, 12001] loss: 0.71300
[  2, 12501] loss: 0.70332
[  2, 13001] loss: 0.68634
[  2, 13501] loss: 0.70055
[  2, 14001] loss: 0.66907
[  2, 14501] loss: 0.67952
[  2, 15001] loss: 0.68356
[  2, 15501] loss: 0.70313
[  2, 16001] loss: 0.69240
[  2, 16501] loss: 0.69629
[  2, 17001] loss: 0.67180
[  2, 17501] loss: 0.68680
[  2, 18001] loss: 0.66244
[  2, 18501] loss: 0.67287
[  2, 19001] loss: 0.67576
[  2, 19501] loss: 0.67692
[  2, 20001] loss: 0.65690
[  2, 20501] loss: 0.67804
[  2, 21001] loss: 0.89458
[  2, 21501] loss: 0.75583
[  2, 22001] loss: 0.69022
[  2, 22501] loss: 0.67280
[  2, 23001] loss: 0.67087
[  2, 23501] loss: 0.68232
[  2, 24001] loss: 0.68630
[  2, 24501] loss: 0.66666
Finished training
Accuracy on train: 0.60784
Accuracy on test: 0.53372
