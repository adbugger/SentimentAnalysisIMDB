{'word_context': 101, 'word_embed_size': 200, 'word_conv_units': 10, 'hidden_units': 5, 'dropout': True, 'batch_size': 500}
2482
train set done
test set done
[  1,     1] loss: 1.21284
[  1,   501] loss: 8.21219
[  1,  1001] loss: 3.90409
[  1,  1501] loss: 1.43401
[  1,  2001] loss: 1.15995
[  1,  2501] loss: 1.08473
[  1,  3001] loss: 0.93405
[  1,  3501] loss: 0.85704
[  1,  4001] loss: 0.91275
[  1,  4501] loss: 0.95524
[  1,  5001] loss: 1.12271
[  1,  5501] loss: 1.22188
[  1,  6001] loss: 8.65010
[  1,  6501] loss: 1.42965
[  1,  7001] loss: 1.49025
[  1,  7501] loss: 1.33776
[  1,  8001] loss: 1.40634
[  1,  8501] loss: 1.18033
[  1,  9001] loss: 1.09442
[  1,  9501] loss: 1.08451
[  1, 10001] loss: 1.14876
[  1, 10501] loss: 0.98253
[  1, 11001] loss: 0.96482
[  1, 11501] loss: 0.95600
[  1, 12001] loss: 1.02567
[  1, 12501] loss: 1.10355
[  1, 13001] loss: 1.20929
[  1, 13501] loss: 1.16574
[  1, 14001] loss: 1.07530
[  1, 14501] loss: 1.29038
[  1, 15001] loss: 1.21176
[  1, 15501] loss: 1.16191
[  1, 16001] loss: 0.99837
[  1, 16501] loss: 0.95053
[  1, 17001] loss: 0.97904
[  1, 17501] loss: 1.18353
[  1, 18001] loss: 1.12493
[  1, 18501] loss: 0.98800
[  1, 19001] loss: 1.00127
[  1, 19501] loss: 1.05393
[  1, 20001] loss: 1.03366
[  1, 20501] loss: 1.05393
[  1, 21001] loss: 1.03923
[  1, 21501] loss: 1.12931
[  1, 22001] loss: 1.15080
[  1, 22501] loss: 1.04818
[  1, 23001] loss: 0.97048
[  1, 23501] loss: 1.02035
[  1, 24001] loss: 1.09437
[  1, 24501] loss: 1.03936
[  2,     1] loss: 0.94353
[  2,   501] loss: 0.81005
[  2,  1001] loss: 0.76699
[  2,  1501] loss: 0.77528
[  2,  2001] loss: 0.74212
[  2,  2501] loss: 0.85526
[  2,  3001] loss: 0.78474
[  2,  3501] loss: 0.79980
[  2,  4001] loss: 0.77438
[  2,  4501] loss: 0.83936
[  2,  5001] loss: 0.80715
[  2,  5501] loss: 0.90126
[  2,  6001] loss: 0.91426
[  2,  6501] loss: 0.96435
[  2,  7001] loss: 0.86387
[  2,  7501] loss: 0.83854
[  2,  8001] loss: 0.81332
[  2,  8501] loss: 0.87912
[  2,  9001] loss: 0.91891
[  2,  9501] loss: 0.83580
[  2, 10001] loss: 0.90464
[  2, 10501] loss: 0.91459
[  2, 11001] loss: 0.89958
[  2, 11501] loss: 0.88584
[  2, 12001] loss: 0.83324
[  2, 12501] loss: 0.82041
[  2, 13001] loss: 0.71908
[  2, 13501] loss: 0.72511
[  2, 14001] loss: 0.73985
[  2, 14501] loss: 0.72909
[  2, 15001] loss: 0.69632
[  2, 15501] loss: 0.70517
[  2, 16001] loss: 0.73621
[  2, 16501] loss: 0.78252
[  2, 17001] loss: 0.86949
[  2, 17501] loss: 0.80039
[  2, 18001] loss: 0.71395
[  2, 18501] loss: 0.72132
[  2, 19001] loss: 0.74120
[  2, 19501] loss: 0.67357
[  2, 20001] loss: 0.78253
[  2, 20501] loss: 0.73315
[  2, 21001] loss: 0.73190
[  2, 21501] loss: 0.73994
[  2, 22001] loss: 0.74676
[  2, 22501] loss: 0.73495
[  2, 23001] loss: 0.74177
[  2, 23501] loss: 0.72328
[  2, 24001] loss: 0.73695
[  2, 24501] loss: 0.73315
Finished training
Accuracy on train: 0.64680
Accuracy on test: 0.53844
