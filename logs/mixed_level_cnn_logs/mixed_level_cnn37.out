{'word_context': 31, 'word_embed_size': 200, 'word_conv_units': 10, 'hidden_units': 5, 'dropout': False, 'batch_size': 500}
2482
train set done
test set done
[  1,     1] loss: 0.80866
[  1,   501] loss: 1.79904
[  1,  1001] loss: 0.93178
[  1,  1501] loss: 0.98555
[  1,  2001] loss: 0.96244
[  1,  2501] loss: 0.87829
[  1,  3001] loss: 0.84896
[  1,  3501] loss: 0.84399
[  1,  4001] loss: 0.84249
[  1,  4501] loss: 0.92945
[  1,  5001] loss: 0.77323
[  1,  5501] loss: 0.75713
[  1,  6001] loss: 0.76537
[  1,  6501] loss: 0.76605
[  1,  7001] loss: 0.76689
[  1,  7501] loss: 0.79247
[  1,  8001] loss: 0.86522
[  1,  8501] loss: 0.83307
[  1,  9001] loss: 0.84238
[  1,  9501] loss: 0.78128
[  1, 10001] loss: 0.74597
[  1, 10501] loss: 0.74346
[  1, 11001] loss: 0.72873
[  1, 11501] loss: 0.71727
[  1, 12001] loss: 0.75388
[  1, 12501] loss: 0.70318
[  1, 13001] loss: 0.75851
[  1, 13501] loss: 0.78726
[  1, 14001] loss: 0.84811
[  1, 14501] loss: 0.77146
[  1, 15001] loss: 0.73484
[  1, 15501] loss: 0.71706
[  1, 16001] loss: 0.69408
[  1, 16501] loss: 0.71603
[  1, 17001] loss: 0.70453
[  1, 17501] loss: 0.72399
[  1, 18001] loss: 0.72810
[  1, 18501] loss: 0.76480
[  1, 19001] loss: 0.85901
[  1, 19501] loss: 0.76393
[  1, 20001] loss: 0.75854
[  1, 20501] loss: 0.79681
[  1, 21001] loss: 0.72353
[  1, 21501] loss: 0.69775
[  1, 22001] loss: 0.70036
[  1, 22501] loss: 0.79320
[  1, 23001] loss: 0.82301
[  1, 23501] loss: 0.77375
[  1, 24001] loss: 0.76668
[  1, 24501] loss: 0.76531
[  2,     1] loss: 0.72650
[  2,   501] loss: 0.73770
[  2,  1001] loss: 0.77084
[  2,  1501] loss: 0.75534
[  2,  2001] loss: 0.77107
[  2,  2501] loss: 0.71377
[  2,  3001] loss: 0.72299
[  2,  3501] loss: 0.71588
[  2,  4001] loss: 0.69521
[  2,  4501] loss: 0.68083
[  2,  5001] loss: 0.65414
[  2,  5501] loss: 0.62014
[  2,  6001] loss: 0.63746
[  2,  6501] loss: 0.61658
[  2,  7001] loss: 0.63145
[  2,  7501] loss: 0.62327
[  2,  8001] loss: 0.64073
[  2,  8501] loss: 0.65918
[  2,  9001] loss: 0.69071
[  2,  9501] loss: 0.67595
[  2, 10001] loss: 0.66789
[  2, 10501] loss: 0.70688
[  2, 11001] loss: 0.64991
[  2, 11501] loss: 0.65024
[  2, 12001] loss: 0.65023
[  2, 12501] loss: 0.61133
[  2, 13001] loss: 0.65950
[  2, 13501] loss: 0.66200
[  2, 14001] loss: 0.70023
[  2, 14501] loss: 0.64737
[  2, 15001] loss: 0.62664
[  2, 15501] loss: 0.60378
[  2, 16001] loss: 0.58186
[  2, 16501] loss: 0.61307
[  2, 17001] loss: 0.58312
[  2, 17501] loss: 0.58103
[  2, 18001] loss: 0.59729
[  2, 18501] loss: 0.58715
[  2, 19001] loss: 0.60644
[  2, 19501] loss: 0.61637
[  2, 20001] loss: 0.69134
[  2, 20501] loss: 0.72919
[  2, 21001] loss: 0.83074
[  2, 21501] loss: 0.83190
[  2, 22001] loss: 0.73366
[  2, 22501] loss: 0.72851
[  2, 23001] loss: 0.71435
[  2, 23501] loss: 0.72670
[  2, 24001] loss: 0.68412
[  2, 24501] loss: 0.64398
Finished training
Accuracy on train: 0.64604
Accuracy on test: 0.55974
