{'word_context': 31, 'word_embed_size': 200, 'word_conv_units': 10, 'hidden_units': 1000, 'dropout': True, 'batch_size': 500}
2482
train set done
test set done
[  1,     1] loss: 0.83106
[  1,   501] loss: 0.88099
[  1,  1001] loss: 2.26393
[  1,  1501] loss: 0.85720
[  1,  2001] loss: 0.81012
[  1,  2501] loss: 0.79418
[  1,  3001] loss: 0.76497
[  1,  3501] loss: 0.73948
[  1,  4001] loss: 0.76082
[  1,  4501] loss: 0.76807
[  1,  5001] loss: 0.74663
[  1,  5501] loss: 0.72113
[  1,  6001] loss: 0.74089
[  1,  6501] loss: 0.73470
[  1,  7001] loss: 0.72103
[  1,  7501] loss: 0.74215
[  1,  8001] loss: 0.72296
[  1,  8501] loss: 0.72791
[  1,  9001] loss: 0.73239
[  1,  9501] loss: 0.73646
[  1, 10001] loss: 0.74375
[  1, 10501] loss: 0.72526
[  1, 11001] loss: 0.72907
[  1, 11501] loss: 0.72651
[  1, 12001] loss: 0.71804
[  1, 12501] loss: 0.70945
[  1, 13001] loss: 0.71221
[  1, 13501] loss: 0.72338
[  1, 14001] loss: 0.70634
[  1, 14501] loss: 0.70249
[  1, 15001] loss: 0.72203
[  1, 15501] loss: 0.70035
[  1, 16001] loss: 0.69624
[  1, 16501] loss: 0.70568
[  1, 17001] loss: 0.70877
[  1, 17501] loss: 0.74267
[  1, 18001] loss: 0.71759
[  1, 18501] loss: 0.71837
[  1, 19001] loss: 0.69995
[  1, 19501] loss: 0.69611
[  1, 20001] loss: 0.69565
[  1, 20501] loss: 0.73139
[  1, 21001] loss: 0.72677
[  1, 21501] loss: 0.70555
[  1, 22001] loss: 0.69945
[  1, 22501] loss: 0.70167
[  1, 23001] loss: 0.70104
[  1, 23501] loss: 0.71197
[  1, 24001] loss: 0.70059
[  1, 24501] loss: 0.73715
[  2,     1] loss: 0.70442
[  2,   501] loss: 0.68639
[  2,  1001] loss: 0.67723
[  2,  1501] loss: 0.70790
[  2,  2001] loss: 0.68135
[  2,  2501] loss: 0.71326
[  2,  3001] loss: 0.71630
[  2,  3501] loss: 0.71363
[  2,  4001] loss: 0.69343
[  2,  4501] loss: 0.69375
[  2,  5001] loss: 0.68309
[  2,  5501] loss: 0.68891
[  2,  6001] loss: 0.68468
[  2,  6501] loss: 0.70770
[  2,  7001] loss: 0.68685
[  2,  7501] loss: 0.69284
[  2,  8001] loss: 0.68382
[  2,  8501] loss: 0.67206
[  2,  9001] loss: 0.69823
[  2,  9501] loss: 0.68514
[  2, 10001] loss: 0.67881
[  2, 10501] loss: 0.67689
[  2, 11001] loss: 0.70054
[  2, 11501] loss: 0.66133
[  2, 12001] loss: 0.71947
[  2, 12501] loss: 0.68885
[  2, 13001] loss: 0.68167
[  2, 13501] loss: 0.69550
[  2, 14001] loss: 0.68580
[  2, 14501] loss: 0.69375
[  2, 15001] loss: 0.69929
[  2, 15501] loss: 0.70098
[  2, 16001] loss: 0.68577
[  2, 16501] loss: 0.70073
[  2, 17001] loss: 0.65932
[  2, 17501] loss: 0.67489
[  2, 18001] loss: 0.67680
[  2, 18501] loss: 0.66950
[  2, 19001] loss: 0.68444
[  2, 19501] loss: 0.68070
[  2, 20001] loss: 0.65776
[  2, 20501] loss: 0.65910
[  2, 21001] loss: 0.68852
[  2, 21501] loss: 0.68606
[  2, 22001] loss: 0.67110
[  2, 22501] loss: 0.68328
[  2, 23001] loss: 0.67023
[  2, 23501] loss: 0.67359
[  2, 24001] loss: 0.70913
[  2, 24501] loss: 0.66332
Finished training
Accuracy on train: 0.64208
Accuracy on test: 0.55638
