{'word_context': 31, 'word_embed_size': 200, 'word_conv_units': 10, 'hidden_units': 5, 'dropout': False, 'batch_size': 500}
2482
train set done
test set done
[  1,     1] loss: 0.70668
[  1,   501] loss: 0.71025
[  1,  1001] loss: 0.73392
[  1,  1501] loss: 0.74978
[  1,  2001] loss: 0.78371
[  1,  2501] loss: 0.80735
[  1,  3001] loss: 0.82780
[  1,  3501] loss: 0.83025
[  1,  4001] loss: 0.75434
[  1,  4501] loss: 0.70364
[  1,  5001] loss: 0.70529
[  1,  5501] loss: 0.68042
[  1,  6001] loss: 0.68486
[  1,  6501] loss: 0.68352
[  1,  7001] loss: 0.68637
[  1,  7501] loss: 0.68132
[  1,  8001] loss: 0.68543
[  1,  8501] loss: 0.67788
[  1,  9001] loss: 0.65104
[  1,  9501] loss: 0.65281
[  1, 10001] loss: 0.67919
[  1, 10501] loss: 0.68491
[  1, 11001] loss: 0.66229
[  1, 11501] loss: 0.70357
[  1, 12001] loss: 0.75416
[  1, 12501] loss: 0.84856
[  1, 13001] loss: 0.81231
[  1, 13501] loss: 0.76243
[  1, 14001] loss: 0.77639
[  1, 14501] loss: 0.73745
[  1, 15001] loss: 0.71136
[  1, 15501] loss: 0.72068
[  1, 16001] loss: 0.73178
[  1, 16501] loss: 0.68942
[  1, 17001] loss: 0.67802
[  1, 17501] loss: 0.70197
[  1, 18001] loss: 0.68354
[  1, 18501] loss: 0.70465
[  1, 19001] loss: 0.70226
[  1, 19501] loss: 0.68452
[  1, 20001] loss: 0.68990
[  1, 20501] loss: 0.69773
[  1, 21001] loss: 0.67012
[  1, 21501] loss: 0.67717
[  1, 22001] loss: 0.66938
[  1, 22501] loss: 0.67247
[  1, 23001] loss: 0.64831
[  1, 23501] loss: 0.63183
[  1, 24001] loss: 0.67789
[  1, 24501] loss: 0.65027
[  2,     1] loss: 0.63767
[  2,   501] loss: 0.67342
[  2,  1001] loss: 0.66080
[  2,  1501] loss: 0.67954
[  2,  2001] loss: 0.68827
[  2,  2501] loss: 0.67383
[  2,  3001] loss: 0.68587
[  2,  3501] loss: 0.67154
[  2,  4001] loss: 0.64714
[  2,  4501] loss: 0.67843
[  2,  5001] loss: 0.71758
[  2,  5501] loss: 0.69900
[  2,  6001] loss: 0.73922
[  2,  6501] loss: 0.65608
[  2,  7001] loss: 0.64528
[  2,  7501] loss: 0.63403
[  2,  8001] loss: 0.62898
[  2,  8501] loss: 0.63920
[  2,  9001] loss: 0.61823
[  2,  9501] loss: 0.61941
[  2, 10001] loss: 0.64092
[  2, 10501] loss: 0.64466
[  2, 11001] loss: 0.59138
[  2, 11501] loss: 0.61071
[  2, 12001] loss: 0.60590
[  2, 12501] loss: 0.62138
[  2, 13001] loss: 0.61998
[  2, 13501] loss: 0.64332
[  2, 14001] loss: 0.62426
[  2, 14501] loss: 0.64925
[  2, 15001] loss: 0.69538
[  2, 15501] loss: 0.64909
[  2, 16001] loss: 0.65882
[  2, 16501] loss: 0.69526
[  2, 17001] loss: 0.64893
[  2, 17501] loss: 0.66677
[  2, 18001] loss: 0.63015
[  2, 18501] loss: 0.63483
[  2, 19001] loss: 0.66281
[  2, 19501] loss: 0.65133
[  2, 20001] loss: 0.67695
[  2, 20501] loss: 0.69003
[  2, 21001] loss: 0.67199
[  2, 21501] loss: 0.67463
[  2, 22001] loss: 0.63134
[  2, 22501] loss: 0.62217
[  2, 23001] loss: 0.60405
[  2, 23501] loss: 0.57909
[  2, 24001] loss: 0.62038
[  2, 24501] loss: 0.59470
Finished training
Accuracy on train: 0.70860
Accuracy on test: 0.57164
