{'word_context': 15, 'word_embed_size': 60, 'word_conv_units': 10, 'hidden_units': 5, 'dropout': True, 'batch_size': 500}
2482
train set done
test set done
[  1,     1] loss: 0.85889
[  1,   501] loss: 0.85304
[  1,  1001] loss: 0.83399
[  1,  1501] loss: 0.76425
[  1,  2001] loss: 0.75865
[  1,  2501] loss: 0.78266
[  1,  3001] loss: 0.79424
[  1,  3501] loss: 0.76491
[  1,  4001] loss: 0.74526
[  1,  4501] loss: 0.76389
[  1,  5001] loss: 0.72697
[  1,  5501] loss: 0.75573
[  1,  6001] loss: 0.73363
[  1,  6501] loss: 0.72777
[  1,  7001] loss: 0.72880
[  1,  7501] loss: 0.73430
[  1,  8001] loss: 0.74387
[  1,  8501] loss: 0.72299
[  1,  9001] loss: 0.71615
[  1,  9501] loss: 0.71477
[  1, 10001] loss: 0.72569
[  1, 10501] loss: 0.68992
[  1, 11001] loss: 0.71740
[  1, 11501] loss: 0.71789
[  1, 12001] loss: 0.73037
[  1, 12501] loss: 0.72087
[  1, 13001] loss: 0.72212
[  1, 13501] loss: 0.69779
[  1, 14001] loss: 0.70707
[  1, 14501] loss: 0.72879
[  1, 15001] loss: 0.72040
[  1, 15501] loss: 0.71470
[  1, 16001] loss: 0.70567
[  1, 16501] loss: 0.70439
[  1, 17001] loss: 0.69105
[  1, 17501] loss: 0.70497
[  1, 18001] loss: 0.70291
[  1, 18501] loss: 0.69830
[  1, 19001] loss: 0.69515
[  1, 19501] loss: 0.69482
[  1, 20001] loss: 0.70516
[  1, 20501] loss: 0.69798
[  1, 21001] loss: 0.70300
[  1, 21501] loss: 0.68863
[  1, 22001] loss: 0.69349
[  1, 22501] loss: 0.68977
[  1, 23001] loss: 0.67770
[  1, 23501] loss: 0.72123
[  1, 24001] loss: 0.69263
[  1, 24501] loss: 0.69156
[  2,     1] loss: 0.70009
[  2,   501] loss: 0.70127
[  2,  1001] loss: 0.70319
[  2,  1501] loss: 0.70508
[  2,  2001] loss: 0.69363
[  2,  2501] loss: 0.69464
[  2,  3001] loss: 0.70272
[  2,  3501] loss: 0.68915
[  2,  4001] loss: 0.69027
[  2,  4501] loss: 0.68312
[  2,  5001] loss: 0.67519
[  2,  5501] loss: 0.70008
[  2,  6001] loss: 0.68969
[  2,  6501] loss: 0.69610
[  2,  7001] loss: 0.68602
[  2,  7501] loss: 0.70459
[  2,  8001] loss: 0.69696
[  2,  8501] loss: 0.69843
[  2,  9001] loss: 0.70692
[  2,  9501] loss: 0.69700
[  2, 10001] loss: 0.69562
[  2, 10501] loss: 0.68039
[  2, 11001] loss: 0.68435
[  2, 11501] loss: 0.67693
[  2, 12001] loss: 0.68888
[  2, 12501] loss: 0.68178
[  2, 13001] loss: 0.68669
[  2, 13501] loss: 0.68189
[  2, 14001] loss: 0.70369
[  2, 14501] loss: 0.69028
[  2, 15001] loss: 0.68660
[  2, 15501] loss: 0.69581
[  2, 16001] loss: 0.68718
[  2, 16501] loss: 0.69339
[  2, 17001] loss: 0.68415
[  2, 17501] loss: 0.68271
[  2, 18001] loss: 0.67095
[  2, 18501] loss: 0.68115
[  2, 19001] loss: 0.69191
[  2, 19501] loss: 0.68312
[  2, 20001] loss: 0.67842
[  2, 20501] loss: 0.67743
[  2, 21001] loss: 0.69771
[  2, 21501] loss: 0.68606
[  2, 22001] loss: 0.69188
[  2, 22501] loss: 0.67555
[  2, 23001] loss: 0.67337
[  2, 23501] loss: 0.69089
[  2, 24001] loss: 0.67018
[  2, 24501] loss: 0.68928
[  3,     1] loss: 0.68090
[  3,   501] loss: 0.67855
[  3,  1001] loss: 0.68277
[  3,  1501] loss: 0.67298
[  3,  2001] loss: 0.68352
[  3,  2501] loss: 0.68448
[  3,  3001] loss: 0.67479
[  3,  3501] loss: 0.68152
[  3,  4001] loss: 0.67132
[  3,  4501] loss: 0.67158
[  3,  5001] loss: 0.67355
[  3,  5501] loss: 0.69265
[  3,  6001] loss: 0.67559
[  3,  6501] loss: 0.67724
[  3,  7001] loss: 0.67848
[  3,  7501] loss: 0.68999
[  3,  8001] loss: 0.68890
[  3,  8501] loss: 0.68551
[  3,  9001] loss: 0.67160
[  3,  9501] loss: 0.68347
[  3, 10001] loss: 0.67058
[  3, 10501] loss: 0.67893
[  3, 11001] loss: 0.69119
[  3, 11501] loss: 0.68178
[  3, 12001] loss: 0.68420
[  3, 12501] loss: 0.67617
[  3, 13001] loss: 0.68248
[  3, 13501] loss: 0.67025
[  3, 14001] loss: 0.68488
[  3, 14501] loss: 0.67138
[  3, 15001] loss: 0.66720
[  3, 15501] loss: 0.67933
[  3, 16001] loss: 0.68012
[  3, 16501] loss: 0.67331
[  3, 17001] loss: 0.67779
[  3, 17501] loss: 0.69614
[  3, 18001] loss: 0.67288
[  3, 18501] loss: 0.68727
[  3, 19001] loss: 0.68181
[  3, 19501] loss: 0.68603
[  3, 20001] loss: 0.68820
[  3, 20501] loss: 0.68090
[  3, 21001] loss: 0.69382
[  3, 21501] loss: 0.68037
[  3, 22001] loss: 0.67339
[  3, 22501] loss: 0.67112
[  3, 23001] loss: 0.67767
[  3, 23501] loss: 0.67808
[  3, 24001] loss: 0.67081
[  3, 24501] loss: 0.67311
[  4,     1] loss: 0.67983
[  4,   501] loss: 0.67189
[  4,  1001] loss: 0.67234
[  4,  1501] loss: 0.68299
[  4,  2001] loss: 0.66691
[  4,  2501] loss: 0.67660
[  4,  3001] loss: 0.68025
[  4,  3501] loss: 0.66857
[  4,  4001] loss: 0.67672
[  4,  4501] loss: 0.68182
[  4,  5001] loss: 0.68101
[  4,  5501] loss: 0.67084
[  4,  6001] loss: 0.66702
[  4,  6501] loss: 0.67571
[  4,  7001] loss: 0.67423
[  4,  7501] loss: 0.68780
[  4,  8001] loss: 0.67237
[  4,  8501] loss: 0.68692
[  4,  9001] loss: 0.67432
[  4,  9501] loss: 0.68924
[  4, 10001] loss: 0.66831
[  4, 10501] loss: 0.68450
[  4, 11001] loss: 0.66821
[  4, 11501] loss: 0.65847
[  4, 12001] loss: 0.68931
[  4, 12501] loss: 0.67094
[  4, 13001] loss: 0.66981
[  4, 13501] loss: 0.67210
[  4, 14001] loss: 0.66844
[  4, 14501] loss: 0.68959
[  4, 15001] loss: 0.68547
[  4, 15501] loss: 0.67947
[  4, 16001] loss: 0.66964
[  4, 16501] loss: 0.68620
[  4, 17001] loss: 0.66547
[  4, 17501] loss: 0.66637
[  4, 18001] loss: 0.66475
[  4, 18501] loss: 0.69725
[  4, 19001] loss: 0.66935
[  4, 19501] loss: 0.67673
[  4, 20001] loss: 0.67889
[  4, 20501] loss: 0.66989
[  4, 21001] loss: 0.66650
[  4, 21501] loss: 0.68618
[  4, 22001] loss: 0.67650
[  4, 22501] loss: 0.68134
[  4, 23001] loss: 0.67541
[  4, 23501] loss: 0.67900
[  4, 24001] loss: 0.66400
[  4, 24501] loss: 0.66510
[  5,     1] loss: 0.68950
[  5,   501] loss: 0.67678
[  5,  1001] loss: 0.66478
[  5,  1501] loss: 0.67585
[  5,  2001] loss: 0.66351
[  5,  2501] loss: 0.66509
[  5,  3001] loss: 0.66602
[  5,  3501] loss: 0.67568
[  5,  4001] loss: 0.67717
[  5,  4501] loss: 0.69373
[  5,  5001] loss: 0.66553
[  5,  5501] loss: 0.67965
[  5,  6001] loss: 0.67338
[  5,  6501] loss: 0.69003
[  5,  7001] loss: 0.67031
[  5,  7501] loss: 0.68547
[  5,  8001] loss: 0.66465
[  5,  8501] loss: 0.67033
[  5,  9001] loss: 0.66248
[  5,  9501] loss: 0.67473
[  5, 10001] loss: 0.66104
[  5, 10501] loss: 0.67031
[  5, 11001] loss: 0.64594
[  5, 11501] loss: 0.65216
[  5, 12001] loss: 0.66732
[  5, 12501] loss: 0.66268
[  5, 13001] loss: 0.66873
[  5, 13501] loss: 0.65634
[  5, 14001] loss: 0.67081
[  5, 14501] loss: 0.64738
[  5, 15001] loss: 0.67979
[  5, 15501] loss: 0.67103
[  5, 16001] loss: 0.67957
[  5, 16501] loss: 0.67760
[  5, 17001] loss: 0.68020
[  5, 17501] loss: 0.67176
[  5, 18001] loss: 0.68421
[  5, 18501] loss: 0.67746
[  5, 19001] loss: 0.67880
[  5, 19501] loss: 0.67876
[  5, 20001] loss: 0.67854
[  5, 20501] loss: 0.64940
[  5, 21001] loss: 0.66019
[  5, 21501] loss: 0.68185
[  5, 22001] loss: 0.66612
[  5, 22501] loss: 0.65806
[  5, 23001] loss: 0.66062
[  5, 23501] loss: 0.68209
[  5, 24001] loss: 0.67077
[  5, 24501] loss: 0.66370
[  6,     1] loss: 0.67350
[  6,   501] loss: 0.69042
[  6,  1001] loss: 0.67638
[  6,  1501] loss: 0.66889
[  6,  2001] loss: 0.66830
[  6,  2501] loss: 0.67953
[  6,  3001] loss: 0.67357
[  6,  3501] loss: 0.67868
[  6,  4001] loss: 0.66537
[  6,  4501] loss: 0.68423
[  6,  5001] loss: 0.65325
[  6,  5501] loss: 0.68950
[  6,  6001] loss: 0.66615
[  6,  6501] loss: 0.67250
[  6,  7001] loss: 0.67486
[  6,  7501] loss: 0.68310
[  6,  8001] loss: 0.68184
[  6,  8501] loss: 0.67875
[  6,  9001] loss: 0.68032
[  6,  9501] loss: 0.68146
[  6, 10001] loss: 0.67070
[  6, 10501] loss: 0.65789
[  6, 11001] loss: 0.66765
[  6, 11501] loss: 0.65889
[  6, 12001] loss: 0.68996
[  6, 12501] loss: 0.65839
[  6, 13001] loss: 0.66313
[  6, 13501] loss: 0.65859
[  6, 14001] loss: 0.68419
[  6, 14501] loss: 0.67027
[  6, 15001] loss: 0.66844
[  6, 15501] loss: 0.67447
[  6, 16001] loss: 0.67607
[  6, 16501] loss: 0.65651
[  6, 17001] loss: 0.65965
[  6, 17501] loss: 0.66102
[  6, 18001] loss: 0.67643
[  6, 18501] loss: 0.68476
[  6, 19001] loss: 0.66702
[  6, 19501] loss: 0.67921
[  6, 20001] loss: 0.67153
[  6, 20501] loss: 0.66306
[  6, 21001] loss: 0.65582
[  6, 21501] loss: 0.66925
[  6, 22001] loss: 0.66730
[  6, 22501] loss: 0.65842
[  6, 23001] loss: 0.66492
[  6, 23501] loss: 0.67268
[  6, 24001] loss: 0.65426
[  6, 24501] loss: 0.64127
[  7,     1] loss: 0.66824
[  7,   501] loss: 0.65795
[  7,  1001] loss: 0.67039
[  7,  1501] loss: 0.65461
[  7,  2001] loss: 0.67877
[  7,  2501] loss: 0.66302
[  7,  3001] loss: 0.65593
[  7,  3501] loss: 0.65355
[  7,  4001] loss: 0.66868
[  7,  4501] loss: 0.67566
[  7,  5001] loss: 0.64996
[  7,  5501] loss: 0.66639
[  7,  6001] loss: 0.66806
[  7,  6501] loss: 0.68086
[  7,  7001] loss: 0.64576
[  7,  7501] loss: 0.68095
[  7,  8001] loss: 0.67892
[  7,  8501] loss: 0.67264
[  7,  9001] loss: 0.67584
[  7,  9501] loss: 0.65628
[  7, 10001] loss: 0.65271
[  7, 10501] loss: 0.65432
[  7, 11001] loss: 0.66913
[  7, 11501] loss: 0.64912
[  7, 12001] loss: 0.67292
[  7, 12501] loss: 0.65966
[  7, 13001] loss: 0.66545
[  7, 13501] loss: 0.65982
[  7, 14001] loss: 0.68254
[  7, 14501] loss: 0.66131
[  7, 15001] loss: 0.67243
[  7, 15501] loss: 0.67371
[  7, 16001] loss: 0.66534
[  7, 16501] loss: 0.67230
[  7, 17001] loss: 0.65209
[  7, 17501] loss: 0.65891
[  7, 18001] loss: 0.64955
[  7, 18501] loss: 0.67799
[  7, 19001] loss: 0.67991
[  7, 19501] loss: 0.67596
[  7, 20001] loss: 0.66978
[  7, 20501] loss: 0.66245
[  7, 21001] loss: 0.66073
[  7, 21501] loss: 0.67255
[  7, 22001] loss: 0.66248
[  7, 22501] loss: 0.66567
[  7, 23001] loss: 0.66767
[  7, 23501] loss: 0.64848
[  7, 24001] loss: 0.64620
[  7, 24501] loss: 0.65320
Finished training
Accuracy on train: 0.60360
Accuracy on test: 0.54264
