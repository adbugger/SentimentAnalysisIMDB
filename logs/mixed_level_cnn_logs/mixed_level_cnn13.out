{'word_context': 15, 'word_embed_size': 500, 'word_conv_units': 10, 'hidden_units': 5, 'dropout': True, 'batch_size': 500}
2482
train set done
test set done
[  1,     1] loss: 0.90009
[  1,   501] loss: 2.14618
[  1,  1001] loss: 1.28570
[  1,  1501] loss: 1.17865
[  1,  2001] loss: 0.95308
[  1,  2501] loss: 0.89632
[  1,  3001] loss: 0.90350
[  1,  3501] loss: 0.89972
[  1,  4001] loss: 0.87134
[  1,  4501] loss: 0.89758
[  1,  5001] loss: 0.75735
[  1,  5501] loss: 0.78193
[  1,  6001] loss: 0.80055
[  1,  6501] loss: 0.80015
[  1,  7001] loss: 0.79038
[  1,  7501] loss: 0.78212
[  1,  8001] loss: 0.74569
[  1,  8501] loss: 0.78541
[  1,  9001] loss: 0.81285
[  1,  9501] loss: 0.77943
[  1, 10001] loss: 0.75355
[  1, 10501] loss: 0.73395
[  1, 11001] loss: 0.76355
[  1, 11501] loss: 0.75384
[  1, 12001] loss: 0.75156
[  1, 12501] loss: 0.80302
[  1, 13001] loss: 0.78440
[  1, 13501] loss: 0.74821
[  1, 14001] loss: 0.74857
[  1, 14501] loss: 0.71298
[  1, 15001] loss: 0.79342
[  1, 15501] loss: 0.76002
[  1, 16001] loss: 0.75218
[  1, 16501] loss: 0.73963
[  1, 17001] loss: 0.75034
[  1, 17501] loss: 0.75966
[  1, 18001] loss: 0.73298
[  1, 18501] loss: 0.72379
[  1, 19001] loss: 0.73280
[  1, 19501] loss: 0.70648
[  1, 20001] loss: 0.73851
[  1, 20501] loss: 0.73714
[  1, 21001] loss: 0.70527
[  1, 21501] loss: 0.69481
[  1, 22001] loss: 0.75982
[  1, 22501] loss: 0.74823
[  1, 23001] loss: 0.73493
[  1, 23501] loss: 0.70471
[  1, 24001] loss: 0.72147
[  1, 24501] loss: 0.71043
[  2,     1] loss: 0.72707
[  2,   501] loss: 0.69683
[  2,  1001] loss: 0.70614
[  2,  1501] loss: 0.69802
[  2,  2001] loss: 0.69879
[  2,  2501] loss: 0.70583
[  2,  3001] loss: 0.70832
[  2,  3501] loss: 0.69814
[  2,  4001] loss: 0.70697
[  2,  4501] loss: 0.69475
[  2,  5001] loss: 0.71500
[  2,  5501] loss: 0.75810
[  2,  6001] loss: 0.70636
[  2,  6501] loss: 0.68043
[  2,  7001] loss: 0.69117
[  2,  7501] loss: 0.69749
[  2,  8001] loss: 0.71035
[  2,  8501] loss: 0.69101
[  2,  9001] loss: 0.71329
[  2,  9501] loss: 0.69574
[  2, 10001] loss: 0.70111
[  2, 10501] loss: 0.68575
[  2, 11001] loss: 0.70407
[  2, 11501] loss: 0.66063
[  2, 12001] loss: 0.69815
[  2, 12501] loss: 0.66980
[  2, 13001] loss: 0.70500
[  2, 13501] loss: 0.69050
[  2, 14001] loss: 0.70482
[  2, 14501] loss: 0.69627
[  2, 15001] loss: 0.70047
[  2, 15501] loss: 0.69572
[  2, 16001] loss: 0.68502
[  2, 16501] loss: 0.68270
[  2, 17001] loss: 0.69573
[  2, 17501] loss: 0.68924
[  2, 18001] loss: 0.67620
[  2, 18501] loss: 0.66099
[  2, 19001] loss: 0.67921
[  2, 19501] loss: 0.67567
[  2, 20001] loss: 0.68436
[  2, 20501] loss: 0.67996
[  2, 21001] loss: 0.66078
[  2, 21501] loss: 0.65199
[  2, 22001] loss: 0.70057
[  2, 22501] loss: 0.66902
[  2, 23001] loss: 0.66703
[  2, 23501] loss: 0.66623
[  2, 24001] loss: 0.65454
[  2, 24501] loss: 0.66728
Finished training
Accuracy on train: 0.63788
Accuracy on test: 0.55662
