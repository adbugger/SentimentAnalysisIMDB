{'word_context': 51, 'word_embed_size': 500, 'word_conv_units': 10, 'hidden_units': 5, 'dropout': True, 'batch_size': 500}
2482
train set done
test set done
[  1,     1] loss: 0.91762
[  1,   501] loss: 2.35189
[  1,  1001] loss: 9.13793
[  1,  1501] loss: 1.57830
[  1,  2001] loss: 1.39790
[  1,  2501] loss: 1.51249
[  1,  3001] loss: 1.31664
[  1,  3501] loss: 1.54633
[  1,  4001] loss: 1.70666
[  1,  4501] loss: 1.37002
[  1,  5001] loss: 1.40209
[  1,  5501] loss: 1.28487
[  1,  6001] loss: 1.08104
[  1,  6501] loss: 1.21072
[  1,  7001] loss: 1.17754
[  1,  7501] loss: 1.12011
[  1,  8001] loss: 1.14395
[  1,  8501] loss: 1.03286
[  1,  9001] loss: 0.99845
[  1,  9501] loss: 0.95807
[  1, 10001] loss: 0.95269
[  1, 10501] loss: 0.93719
[  1, 11001] loss: 0.98835
[  1, 11501] loss: 1.04314
[  1, 12001] loss: 0.94361
[  1, 12501] loss: 0.93857
[  1, 13001] loss: 0.97160
[  1, 13501] loss: 0.88813
[  1, 14001] loss: 0.88281
[  1, 14501] loss: 0.92849
[  1, 15001] loss: 0.90977
[  1, 15501] loss: 0.86358
[  1, 16001] loss: 0.87888
[  1, 16501] loss: 0.91696
[  1, 17001] loss: 0.83421
[  1, 17501] loss: 0.86788
[  1, 18001] loss: 0.95617
[  1, 18501] loss: 0.94474
[  1, 19001] loss: 0.94754
[  1, 19501] loss: 1.05730
[  1, 20001] loss: 0.88252
[  1, 20501] loss: 0.92569
[  1, 21001] loss: 0.90245
[  1, 21501] loss: 0.86401
[  1, 22001] loss: 0.84697
[  1, 22501] loss: 0.92234
[  1, 23001] loss: 0.99342
[  1, 23501] loss: 0.90991
[  1, 24001] loss: 1.14743
[  1, 24501] loss: 0.99749
[  2,     1] loss: 0.91927
[  2,   501] loss: 0.88763
[  2,  1001] loss: 0.75817
[  2,  1501] loss: 0.77809
[  2,  2001] loss: 0.77693
[  2,  2501] loss: 0.75398
[  2,  3001] loss: 0.75773
[  2,  3501] loss: 0.82682
[  2,  4001] loss: 0.83371
[  2,  4501] loss: 0.86669
[  2,  5001] loss: 0.78808
[  2,  5501] loss: 0.81081
[  2,  6001] loss: 0.79712
[  2,  6501] loss: 0.81958
[  2,  7001] loss: 0.75613
[  2,  7501] loss: 0.73450
[  2,  8001] loss: 0.76341
[  2,  8501] loss: 0.70510
[  2,  9001] loss: 0.73346
[  2,  9501] loss: 0.78767
[  2, 10001] loss: 0.80017
[  2, 10501] loss: 0.78256
[  2, 11001] loss: 0.76147
[  2, 11501] loss: 0.72028
[  2, 12001] loss: 0.79344
[  2, 12501] loss: 0.77246
[  2, 13001] loss: 0.72529
[  2, 13501] loss: 0.74061
[  2, 14001] loss: 0.70354
[  2, 14501] loss: 0.74477
[  2, 15001] loss: 0.69427
[  2, 15501] loss: 0.84008
[  2, 16001] loss: 0.80946
[  2, 16501] loss: 0.72342
[  2, 17001] loss: 0.69707
[  2, 17501] loss: 0.69497
[  2, 18001] loss: 0.67467
[  2, 18501] loss: 0.67327
[  2, 19001] loss: 0.68482
[  2, 19501] loss: 0.69803
[  2, 20001] loss: 0.69543
[  2, 20501] loss: 0.68579
[  2, 21001] loss: 0.66620
[  2, 21501] loss: 0.68298
[  2, 22001] loss: 0.65768
[  2, 22501] loss: 0.68314
[  2, 23001] loss: 0.65112
[  2, 23501] loss: 0.66745
[  2, 24001] loss: 0.65921
[  2, 24501] loss: 0.67176
Finished training
Accuracy on train: 0.66576
Accuracy on test: 0.54782
