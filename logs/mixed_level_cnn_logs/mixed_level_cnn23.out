{'word_context': 15, 'word_embed_size': 500, 'word_conv_units': 500, 'hidden_units': 5, 'dropout': True, 'batch_size': 500}
2482
train set done
test set done
[  1,     1] loss: 0.87494
[  1,   501] loss: 5.64353
[  1,  1001] loss: 16.56083
[  1,  1501] loss: 2.81022
[  1,  2001] loss: 6.72061
[  1,  2501] loss: 1.98327
[  1,  3001] loss: 4.82826
[  1,  3501] loss: 2.17290
[  1,  4001] loss: 3.62354
[  1,  4501] loss: 2.03503
[  1,  5001] loss: 2.23316
[  1,  5501] loss: 2.15416
[  1,  6001] loss: 1.68724
[  1,  6501] loss: 1.54532
[  1,  7001] loss: 1.14128
[  1,  7501] loss: 1.15328
[  1,  8001] loss: 1.26755
[  1,  8501] loss: 0.99942
[  1,  9001] loss: 0.98875
[  1,  9501] loss: 1.12355
[  1, 10001] loss: 1.07354
[  1, 10501] loss: 0.96150
[  1, 11001] loss: 0.85754
[  1, 11501] loss: 0.77220
[  1, 12001] loss: 0.76862
[  1, 12501] loss: 0.79912
[  1, 13001] loss: 0.81259
[  1, 13501] loss: 0.90199
[  1, 14001] loss: 0.96863
[  1, 14501] loss: 0.82432
[  1, 15001] loss: 0.75088
[  1, 15501] loss: 0.77821
[  1, 16001] loss: 0.75819
[  1, 16501] loss: 0.81581
[  1, 17001] loss: 0.87273
[  1, 17501] loss: 0.87339
[  1, 18001] loss: 0.90370
[  1, 18501] loss: 0.87737
[  1, 19001] loss: 0.81901
[  1, 19501] loss: 0.79672
[  1, 20001] loss: 0.78519
[  1, 20501] loss: 0.75972
[  1, 21001] loss: 0.74739
[  1, 21501] loss: 0.74855
[  1, 22001] loss: 0.75068
[  1, 22501] loss: 0.74288
[  1, 23001] loss: 0.73925
[  1, 23501] loss: 0.73238
[  1, 24001] loss: 0.72544
[  1, 24501] loss: 0.76443
[  2,     1] loss: 0.79439
[  2,   501] loss: 0.80318
[  2,  1001] loss: 0.69742
[  2,  1501] loss: 0.67830
[  2,  2001] loss: 0.61042
[  2,  2501] loss: 0.61479
[  2,  3001] loss: 0.65367
[  2,  3501] loss: 0.75032
[  2,  4001] loss: 0.84171
[  2,  4501] loss: 0.89005
[  2,  5001] loss: 0.86268
[  2,  5501] loss: 0.71268
[  2,  6001] loss: 0.64746
[  2,  6501] loss: 0.65366
[  2,  7001] loss: 0.71385
[  2,  7501] loss: 0.72281
[  2,  8001] loss: 0.70890
[  2,  8501] loss: 0.73872
[  2,  9001] loss: 0.71543
[  2,  9501] loss: 0.66107
[  2, 10001] loss: 0.63499
[  2, 10501] loss: 0.67519
[  2, 11001] loss: 0.69169
[  2, 11501] loss: 0.77545
[  2, 12001] loss: 0.76854
[  2, 12501] loss: 0.68178
[  2, 13001] loss: 0.62886
[  2, 13501] loss: 0.60694
[  2, 14001] loss: 0.61167
[  2, 14501] loss: 0.65617
[  2, 15001] loss: 0.68545
[  2, 15501] loss: 0.64521
[  2, 16001] loss: 0.67572
[  2, 16501] loss: 0.65158
[  2, 17001] loss: 0.62207
[  2, 17501] loss: 0.63388
[  2, 18001] loss: 0.62909
[  2, 18501] loss: 0.64397
[  2, 19001] loss: 0.72965
[  2, 19501] loss: 0.72842
[  2, 20001] loss: 0.67085
[  2, 20501] loss: 0.64132
[  2, 21001] loss: 0.63968
[  2, 21501] loss: 0.66375
[  2, 22001] loss: 0.65863
[  2, 22501] loss: 0.69636
[  2, 23001] loss: 0.69582
[  2, 23501] loss: 0.70423
[  2, 24001] loss: 0.67949
[  2, 24501] loss: 0.63804
Finished training
