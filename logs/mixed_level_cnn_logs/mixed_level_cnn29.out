{'word_context': 15, 'word_embed_size': 500, 'word_conv_units': 10, 'hidden_units': 5, 'dropout': False, 'batch_size': 500}
2482
train set done
test set done
[  1,     1] loss: 0.89149
[  1,   501] loss: 1.14434
[  1,  1001] loss: 1.00379
[  1,  1501] loss: 1.19606
[  1,  2001] loss: 1.30122
[  1,  2501] loss: 0.98457
[  1,  3001] loss: 0.94541
[  1,  3501] loss: 0.85908
[  1,  4001] loss: 0.89109
[  1,  4501] loss: 0.86550
[  1,  5001] loss: 0.97819
[  1,  5501] loss: 0.83230
[  1,  6001] loss: 0.85457
[  1,  6501] loss: 0.84506
[  1,  7001] loss: 0.82244
[  1,  7501] loss: 0.80763
[  1,  8001] loss: 0.78760
[  1,  8501] loss: 0.76862
[  1,  9001] loss: 0.79180
[  1,  9501] loss: 0.77569
[  1, 10001] loss: 0.82531
[  1, 10501] loss: 0.82516
[  1, 11001] loss: 0.82343
[  1, 11501] loss: 0.90154
[  1, 12001] loss: 0.95432
[  1, 12501] loss: 0.82975
[  1, 13001] loss: 0.76109
[  1, 13501] loss: 0.74010
[  1, 14001] loss: 0.74212
[  1, 14501] loss: 0.72244
[  1, 15001] loss: 0.71392
[  1, 15501] loss: 0.69337
[  1, 16001] loss: 0.70850
[  1, 16501] loss: 0.71521
[  1, 17001] loss: 0.91354
[  1, 17501] loss: 1.05989
[  1, 18001] loss: 0.80898
[  1, 18501] loss: 0.79036
[  1, 19001] loss: 0.78609
[  1, 19501] loss: 0.76979
[  1, 20001] loss: 0.74530
[  1, 20501] loss: 0.79196
[  1, 21001] loss: 0.78595
[  1, 21501] loss: 0.75675
[  1, 22001] loss: 0.71060
[  1, 22501] loss: 0.72384
[  1, 23001] loss: 0.86157
[  1, 23501] loss: 0.93621
[  1, 24001] loss: 0.74121
[  1, 24501] loss: 0.71223
[  2,     1] loss: 0.69898
[  2,   501] loss: 0.69743
[  2,  1001] loss: 0.72239
[  2,  1501] loss: 0.69686
[  2,  2001] loss: 0.73361
[  2,  2501] loss: 0.74387
[  2,  3001] loss: 0.74336
[  2,  3501] loss: 0.71220
[  2,  4001] loss: 0.81589
[  2,  4501] loss: 0.85937
[  2,  5001] loss: 0.83173
[  2,  5501] loss: 0.73135
[  2,  6001] loss: 0.70456
[  2,  6501] loss: 0.67968
[  2,  7001] loss: 0.70063
[  2,  7501] loss: 0.69864
[  2,  8001] loss: 0.68728
[  2,  8501] loss: 0.66319
[  2,  9001] loss: 0.65693
[  2,  9501] loss: 0.69944
[  2, 10001] loss: 0.73566
[  2, 10501] loss: 0.76649
[  2, 11001] loss: 0.79366
[  2, 11501] loss: 0.92729
[  2, 12001] loss: 0.83656
[  2, 12501] loss: 0.72822
[  2, 13001] loss: 0.68127
[  2, 13501] loss: 0.65059
[  2, 14001] loss: 0.64794
[  2, 14501] loss: 0.63253
[  2, 15001] loss: 0.64687
[  2, 15501] loss: 0.64044
[  2, 16001] loss: 0.64049
[  2, 16501] loss: 0.61900
[  2, 17001] loss: 0.66005
[  2, 17501] loss: 0.74502
[  2, 18001] loss: 0.78688
[  2, 18501] loss: 0.79887
[  2, 19001] loss: 0.78709
[  2, 19501] loss: 0.76203
[  2, 20001] loss: 0.75384
[  2, 20501] loss: 0.73689
[  2, 21001] loss: 0.75302
[  2, 21501] loss: 0.77390
[  2, 22001] loss: 0.79275
[  2, 22501] loss: 0.71383
[  2, 23001] loss: 0.70775
[  2, 23501] loss: 0.70946
[  2, 24001] loss: 0.73305
[  2, 24501] loss: 0.75488
Finished training
Accuracy on train: 0.59972
Accuracy on test: 0.52674
