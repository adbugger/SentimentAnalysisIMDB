{'word_context': 51, 'word_embed_size': 200, 'word_conv_units': 10, 'hidden_units': 5, 'dropout': True, 'batch_size': 500}
2482
train set done
test set done
[  1,     1] loss: 1.13979
[  1,   501] loss: 1.57995
[  1,  1001] loss: 1.35538
[  1,  1501] loss: 1.00593
[  1,  2001] loss: 1.01136
[  1,  2501] loss: 0.99563
[  1,  3001] loss: 2.23860
[  1,  3501] loss: 1.12992
[  1,  4001] loss: 0.91318
[  1,  4501] loss: 0.85761
[  1,  5001] loss: 0.79085
[  1,  5501] loss: 0.78968
[  1,  6001] loss: 0.75687
[  1,  6501] loss: 0.79163
[  1,  7001] loss: 0.80476
[  1,  7501] loss: 0.78925
[  1,  8001] loss: 0.79060
[  1,  8501] loss: 0.77822
[  1,  9001] loss: 0.76543
[  1,  9501] loss: 0.79022
[  1, 10001] loss: 0.75693
[  1, 10501] loss: 0.73477
[  1, 11001] loss: 0.77342
[  1, 11501] loss: 0.74817
[  1, 12001] loss: 0.75682
[  1, 12501] loss: 0.74987
[  1, 13001] loss: 0.82713
[  1, 13501] loss: 0.85958
[  1, 14001] loss: 0.77427
[  1, 14501] loss: 0.78824
[  1, 15001] loss: 0.74725
[  1, 15501] loss: 0.74485
[  1, 16001] loss: 0.83483
[  1, 16501] loss: 0.85741
[  1, 17001] loss: 0.80674
[  1, 17501] loss: 0.80543
[  1, 18001] loss: 1.00095
[  1, 18501] loss: 0.93107
[  1, 19001] loss: 0.77062
[  1, 19501] loss: 0.77107
[  1, 20001] loss: 0.78591
[  1, 20501] loss: 0.76812
[  1, 21001] loss: 0.75813
[  1, 21501] loss: 0.72956
[  1, 22001] loss: 0.74738
[  1, 22501] loss: 0.72118
[  1, 23001] loss: 0.76026
[  1, 23501] loss: 0.74749
[  1, 24001] loss: 0.72903
[  1, 24501] loss: 0.74400
[  2,     1] loss: 0.70421
[  2,   501] loss: 0.68325
[  2,  1001] loss: 0.74606
[  2,  1501] loss: 0.73277
[  2,  2001] loss: 0.72918
[  2,  2501] loss: 0.72596
[  2,  3001] loss: 0.71560
[  2,  3501] loss: 0.69779
[  2,  4001] loss: 0.72700
[  2,  4501] loss: 0.71042
[  2,  5001] loss: 0.71317
[  2,  5501] loss: 0.73413
[  2,  6001] loss: 0.71804
[  2,  6501] loss: 0.71303
[  2,  7001] loss: 0.69728
[  2,  7501] loss: 0.71181
[  2,  8001] loss: 0.70503
[  2,  8501] loss: 0.70117
[  2,  9001] loss: 0.70670
[  2,  9501] loss: 0.72898
[  2, 10001] loss: 0.71054
[  2, 10501] loss: 0.69954
[  2, 11001] loss: 0.68825
[  2, 11501] loss: 0.69061
[  2, 12001] loss: 0.68637
[  2, 12501] loss: 0.70517
[  2, 13001] loss: 0.70129
[  2, 13501] loss: 0.70093
[  2, 14001] loss: 0.68649
[  2, 14501] loss: 0.67481
[  2, 15001] loss: 0.68631
[  2, 15501] loss: 0.66244
[  2, 16001] loss: 0.69426
[  2, 16501] loss: 0.66095
[  2, 17001] loss: 0.68826
[  2, 17501] loss: 0.65411
[  2, 18001] loss: 0.66301
[  2, 18501] loss: 0.67788
[  2, 19001] loss: 0.67451
[  2, 19501] loss: 0.66972
[  2, 20001] loss: 0.66519
[  2, 20501] loss: 0.69848
[  2, 21001] loss: 0.66358
[  2, 21501] loss: 0.66781
[  2, 22001] loss: 0.66538
[  2, 22501] loss: 0.63726
[  2, 23001] loss: 0.66229
[  2, 23501] loss: 0.66595
[  2, 24001] loss: 0.63997
[  2, 24501] loss: 0.65577
Finished training
Accuracy on train: 0.66096
Accuracy on test: 0.56044
