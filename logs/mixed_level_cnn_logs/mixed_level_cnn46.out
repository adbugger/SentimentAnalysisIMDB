{'word_context': 31, 'word_embed_size': 200, 'word_conv_units': 10, 'hidden_units': 50, 'dropout': True, 'batch_size': 500}
2482
train set done
test set done
[  1,     1] loss: 1.20477
[  1,   501] loss: 0.88409
[  1,  1001] loss: 0.93138
[  1,  1501] loss: 0.80025
[  1,  2001] loss: 0.79689
[  1,  2501] loss: 0.83064
[  1,  3001] loss: 0.79953
[  1,  3501] loss: 0.77638
[  1,  4001] loss: 0.76728
[  1,  4501] loss: 0.75318
[  1,  5001] loss: 0.80065
[  1,  5501] loss: 0.81302
[  1,  6001] loss: 0.76196
[  1,  6501] loss: 0.77868
[  1,  7001] loss: 0.76861
[  1,  7501] loss: 0.88466
[  1,  8001] loss: 0.78691
[  1,  8501] loss: 0.74655
[  1,  9001] loss: 0.72721
[  1,  9501] loss: 0.76996
[  1, 10001] loss: 0.76208
[  1, 10501] loss: 0.73835
[  1, 11001] loss: 0.75246
[  1, 11501] loss: 0.73231
[  1, 12001] loss: 0.81870
[  1, 12501] loss: 0.80578
[  1, 13001] loss: 0.76890
[  1, 13501] loss: 0.74166
[  1, 14001] loss: 0.73127
[  1, 14501] loss: 0.75243
[  1, 15001] loss: 0.72645
[  1, 15501] loss: 0.76266
[  1, 16001] loss: 0.78117
[  1, 16501] loss: 0.74613
[  1, 17001] loss: 0.70738
[  1, 17501] loss: 0.74379
[  1, 18001] loss: 0.75104
[  1, 18501] loss: 0.73376
[  1, 19001] loss: 0.72552
[  1, 19501] loss: 0.71609
[  1, 20001] loss: 0.72004
[  1, 20501] loss: 0.73009
[  1, 21001] loss: 0.75076
[  1, 21501] loss: 0.72418
[  1, 22001] loss: 0.74451
[  1, 22501] loss: 0.70100
[  1, 23001] loss: 0.73534
[  1, 23501] loss: 0.70979
[  1, 24001] loss: 0.71357
[  1, 24501] loss: 0.72170
[  2,     1] loss: 0.70279
[  2,   501] loss: 0.67953
[  2,  1001] loss: 0.71979
[  2,  1501] loss: 0.71296
[  2,  2001] loss: 0.69293
[  2,  2501] loss: 0.69518
[  2,  3001] loss: 0.69088
[  2,  3501] loss: 0.71058
[  2,  4001] loss: 0.72300
[  2,  4501] loss: 0.70099
[  2,  5001] loss: 0.73104
[  2,  5501] loss: 0.70118
[  2,  6001] loss: 0.69388
[  2,  6501] loss: 0.67154
[  2,  7001] loss: 0.72759
[  2,  7501] loss: 0.67984
[  2,  8001] loss: 0.69600
[  2,  8501] loss: 0.71432
[  2,  9001] loss: 0.67652
[  2,  9501] loss: 0.69342
[  2, 10001] loss: 0.68027
[  2, 10501] loss: 0.67677
[  2, 11001] loss: 0.66003
[  2, 11501] loss: 0.71146
[  2, 12001] loss: 0.71418
[  2, 12501] loss: 0.68526
[  2, 13001] loss: 0.67263
[  2, 13501] loss: 0.69041
[  2, 14001] loss: 0.70725
[  2, 14501] loss: 0.65668
[  2, 15001] loss: 0.66427
[  2, 15501] loss: 0.66813
[  2, 16001] loss: 0.69230
[  2, 16501] loss: 0.68192
[  2, 17001] loss: 0.65874
[  2, 17501] loss: 0.65727
[  2, 18001] loss: 0.70357
[  2, 18501] loss: 0.66418
[  2, 19001] loss: 0.67494
[  2, 19501] loss: 0.67156
[  2, 20001] loss: 0.67865
[  2, 20501] loss: 0.68180
[  2, 21001] loss: 0.68147
[  2, 21501] loss: 0.68938
[  2, 22001] loss: 0.66255
[  2, 22501] loss: 0.65492
[  2, 23001] loss: 0.66388
[  2, 23501] loss: 0.69082
[  2, 24001] loss: 0.66484
[  2, 24501] loss: 0.64857
Finished training
Accuracy on train: 0.64284
Accuracy on test: 0.55574
