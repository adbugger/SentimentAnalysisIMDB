{'word_context': 31, 'word_embed_size': 200, 'word_conv_units': 10, 'hidden_units': 5, 'dropout': False, 'batch_size': 500}
2482
train set done
test set done
[  1,     1] loss: 1.04612
[  1,   501] loss: 1.23334
[  1,  1001] loss: 0.91350
[  1,  1501] loss: 0.72127
[  1,  2001] loss: 0.71644
[  1,  2501] loss: 0.70618
[  1,  3001] loss: 0.71380
[  1,  3501] loss: 0.71830
[  1,  4001] loss: 0.70910
[  1,  4501] loss: 0.71971
[  1,  5001] loss: 0.82479
[  1,  5501] loss: 0.81106
[  1,  6001] loss: 0.72151
[  1,  6501] loss: 0.71105
[  1,  7001] loss: 0.72539
[  1,  7501] loss: 0.73273
[  1,  8001] loss: 0.73903
[  1,  8501] loss: 0.77383
[  1,  9001] loss: 0.79463
[  1,  9501] loss: 0.82096
[  1, 10001] loss: 0.74584
[  1, 10501] loss: 0.70674
[  1, 11001] loss: 0.68226
[  1, 11501] loss: 0.70861
[  1, 12001] loss: 0.72998
[  1, 12501] loss: 0.70715
[  1, 13001] loss: 0.72074
[  1, 13501] loss: 0.79045
[  1, 14001] loss: 0.78335
[  1, 14501] loss: 0.75430
[  1, 15001] loss: 0.74539
[  1, 15501] loss: 0.74329
[  1, 16001] loss: 0.76224
[  1, 16501] loss: 0.81319
[  1, 17001] loss: 0.72604
[  1, 17501] loss: 0.68631
[  1, 18001] loss: 0.71239
[  1, 18501] loss: 0.67972
[  1, 19001] loss: 0.69857
[  1, 19501] loss: 0.68523
[  1, 20001] loss: 0.69713
[  1, 20501] loss: 0.66501
[  1, 21001] loss: 0.67388
[  1, 21501] loss: 0.64625
[  1, 22001] loss: 0.70036
[  1, 22501] loss: 0.72242
[  1, 23001] loss: 0.78450
[  1, 23501] loss: 0.91145
[  1, 24001] loss: 0.83481
[  1, 24501] loss: 0.68830
[  2,     1] loss: 0.69038
[  2,   501] loss: 0.69927
[  2,  1001] loss: 0.66140
[  2,  1501] loss: 0.63361
[  2,  2001] loss: 0.65287
[  2,  2501] loss: 0.68651
[  2,  3001] loss: 0.67532
[  2,  3501] loss: 0.64845
[  2,  4001] loss: 0.65443
[  2,  4501] loss: 0.69728
[  2,  5001] loss: 0.66858
[  2,  5501] loss: 0.66992
[  2,  6001] loss: 0.65931
[  2,  6501] loss: 0.71241
[  2,  7001] loss: 0.71713
[  2,  7501] loss: 0.69494
[  2,  8001] loss: 0.67078
[  2,  8501] loss: 0.68489
[  2,  9001] loss: 0.68637
[  2,  9501] loss: 0.69187
[  2, 10001] loss: 0.67320
[  2, 10501] loss: 0.73496
[  2, 11001] loss: 0.78008
[  2, 11501] loss: 0.73950
[  2, 12001] loss: 0.67416
[  2, 12501] loss: 0.64658
[  2, 13001] loss: 0.64182
[  2, 13501] loss: 0.62709
[  2, 14001] loss: 0.62388
[  2, 14501] loss: 0.63299
[  2, 15001] loss: 0.64909
[  2, 15501] loss: 0.66223
[  2, 16001] loss: 0.64258
[  2, 16501] loss: 0.66720
[  2, 17001] loss: 0.63252
[  2, 17501] loss: 0.66143
[  2, 18001] loss: 0.70199
[  2, 18501] loss: 0.66599
[  2, 19001] loss: 0.66817
[  2, 19501] loss: 0.66299
[  2, 20001] loss: 0.70597
[  2, 20501] loss: 0.64977
[  2, 21001] loss: 0.63746
[  2, 21501] loss: 0.62055
[  2, 22001] loss: 0.61962
[  2, 22501] loss: 0.62564
[  2, 23001] loss: 0.61503
[  2, 23501] loss: 0.58913
[  2, 24001] loss: 0.61080
[  2, 24501] loss: 0.60054
Finished training
Accuracy on train: 0.68560
Accuracy on test: 0.56196
