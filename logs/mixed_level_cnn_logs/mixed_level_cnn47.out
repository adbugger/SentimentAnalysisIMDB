{'word_context': 31, 'word_embed_size': 200, 'word_conv_units': 10, 'hidden_units': 500, 'dropout': True, 'batch_size': 500}
2482
train set done
test set done
[  1,     1] loss: 0.77856
[  1,   501] loss: 0.75477
[  1,  1001] loss: 0.73134
[  1,  1501] loss: 0.76030
[  1,  2001] loss: 0.75809
[  1,  2501] loss: 0.80343
[  1,  3001] loss: 0.76462
[  1,  3501] loss: 0.71909
[  1,  4001] loss: 0.71941
[  1,  4501] loss: 0.72733
[  1,  5001] loss: 0.69324
[  1,  5501] loss: 0.72328
[  1,  6001] loss: 0.72411
[  1,  6501] loss: 0.70818
[  1,  7001] loss: 0.71175
[  1,  7501] loss: 0.69383
[  1,  8001] loss: 0.70364
[  1,  8501] loss: 0.68267
[  1,  9001] loss: 0.71979
[  1,  9501] loss: 0.69186
[  1, 10001] loss: 0.71436
[  1, 10501] loss: 0.70451
[  1, 11001] loss: 0.70976
[  1, 11501] loss: 0.68810
[  1, 12001] loss: 0.71642
[  1, 12501] loss: 0.68226
[  1, 13001] loss: 0.70030
[  1, 13501] loss: 0.69257
[  1, 14001] loss: 0.73841
[  1, 14501] loss: 0.71217
[  1, 15001] loss: 0.70246
[  1, 15501] loss: 0.70610
[  1, 16001] loss: 0.68017
[  1, 16501] loss: 0.70418
[  1, 17001] loss: 0.68358
[  1, 17501] loss: 0.67432
[  1, 18001] loss: 0.68866
[  1, 18501] loss: 0.69079
[  1, 19001] loss: 0.70568
[  1, 19501] loss: 0.68282
[  1, 20001] loss: 0.68943
[  1, 20501] loss: 0.69071
[  1, 21001] loss: 0.69614
[  1, 21501] loss: 0.69945
[  1, 22001] loss: 0.67971
[  1, 22501] loss: 0.67628
[  1, 23001] loss: 0.68169
[  1, 23501] loss: 0.68818
[  1, 24001] loss: 0.68299
[  1, 24501] loss: 0.69272
[  2,     1] loss: 0.67924
[  2,   501] loss: 0.69204
[  2,  1001] loss: 0.66723
[  2,  1501] loss: 0.67640
[  2,  2001] loss: 0.69777
[  2,  2501] loss: 0.67042
[  2,  3001] loss: 0.67073
[  2,  3501] loss: 0.68738
[  2,  4001] loss: 0.67402
[  2,  4501] loss: 0.68176
[  2,  5001] loss: 0.67453
[  2,  5501] loss: 0.68088
[  2,  6001] loss: 0.67456
[  2,  6501] loss: 0.67095
[  2,  7001] loss: 0.68594
[  2,  7501] loss: 0.67358
[  2,  8001] loss: 0.67968
[  2,  8501] loss: 0.65959
[  2,  9001] loss: 0.68245
[  2,  9501] loss: 0.68056
[  2, 10001] loss: 0.69887
[  2, 10501] loss: 0.66959
[  2, 11001] loss: 0.67190
[  2, 11501] loss: 0.67757
[  2, 12001] loss: 0.68039
[  2, 12501] loss: 0.65828
[  2, 13001] loss: 0.66881
[  2, 13501] loss: 0.67606
[  2, 14001] loss: 0.64744
[  2, 14501] loss: 0.66349
[  2, 15001] loss: 0.66779
[  2, 15501] loss: 0.66375
[  2, 16001] loss: 0.64102
[  2, 16501] loss: 0.66097
[  2, 17001] loss: 0.65312
[  2, 17501] loss: 0.66056
[  2, 18001] loss: 0.66710
[  2, 18501] loss: 0.66445
[  2, 19001] loss: 0.66939
[  2, 19501] loss: 0.65257
[  2, 20001] loss: 0.65407
[  2, 20501] loss: 0.65970
[  2, 21001] loss: 0.64844
[  2, 21501] loss: 0.66608
[  2, 22001] loss: 0.66108
[  2, 22501] loss: 0.64334
[  2, 23001] loss: 0.63115
[  2, 23501] loss: 0.64401
[  2, 24001] loss: 0.63888
[  2, 24501] loss: 0.65403
Finished training
Accuracy on train: 0.64384
Accuracy on test: 0.55826
