{'word_context': 15, 'word_embed_size': 200, 'word_conv_units': 10, 'hidden_units': 5, 'dropout': False, 'batch_size': 500}
2482
train set done
test set done
[  1,     1] loss: 0.94823
[  1,   501] loss: 0.73140
[  1,  1001] loss: 0.70975
[  1,  1501] loss: 0.70694
[  1,  2001] loss: 0.70602
[  1,  2501] loss: 0.70442
[  1,  3001] loss: 0.71366
[  1,  3501] loss: 1.14443
[  1,  4001] loss: 0.90569
[  1,  4501] loss: 0.73147
[  1,  5001] loss: 0.70794
[  1,  5501] loss: 0.71003
[  1,  6001] loss: 0.71878
[  1,  6501] loss: 0.71571
[  1,  7001] loss: 0.69729
[  1,  7501] loss: 0.70598
[  1,  8001] loss: 0.69988
[  1,  8501] loss: 0.69644
[  1,  9001] loss: 0.72418
[  1,  9501] loss: 0.68561
[  1, 10001] loss: 0.69429
[  1, 10501] loss: 0.69300
[  1, 11001] loss: 0.70899
[  1, 11501] loss: 0.75719
[  1, 12001] loss: 0.74374
[  1, 12501] loss: 0.73259
[  1, 13001] loss: 0.72880
[  1, 13501] loss: 0.72434
[  1, 14001] loss: 0.69940
[  1, 14501] loss: 0.69351
[  1, 15001] loss: 0.69411
[  1, 15501] loss: 0.67588
[  1, 16001] loss: 0.67733
[  1, 16501] loss: 0.71935
[  1, 17001] loss: 0.70457
[  1, 17501] loss: 0.73252
[  1, 18001] loss: 0.73443
[  1, 18501] loss: 0.77591
[  1, 19001] loss: 0.74327
[  1, 19501] loss: 0.68203
[  1, 20001] loss: 0.70495
[  1, 20501] loss: 0.68055
[  1, 21001] loss: 0.68675
[  1, 21501] loss: 0.72898
[  1, 22001] loss: 0.72061
[  1, 22501] loss: 0.73623
[  1, 23001] loss: 0.75763
[  1, 23501] loss: 0.74855
[  1, 24001] loss: 0.75756
[  1, 24501] loss: 0.75269
[  2,     1] loss: 0.75624
[  2,   501] loss: 0.71143
[  2,  1001] loss: 0.67946
[  2,  1501] loss: 0.66296
[  2,  2001] loss: 0.67094
[  2,  2501] loss: 0.65735
[  2,  3001] loss: 0.65361
[  2,  3501] loss: 0.64514
[  2,  4001] loss: 0.64709
[  2,  4501] loss: 0.65124
[  2,  5001] loss: 0.62901
[  2,  5501] loss: 0.64758
[  2,  6001] loss: 0.63250
[  2,  6501] loss: 0.64279
[  2,  7001] loss: 0.62498
[  2,  7501] loss: 0.63604
[  2,  8001] loss: 0.63939
[  2,  8501] loss: 0.65680
[  2,  9001] loss: 0.70141
[  2,  9501] loss: 0.74682
[  2, 10001] loss: 0.72730
[  2, 10501] loss: 0.68960
[  2, 11001] loss: 0.68384
[  2, 11501] loss: 0.68544
[  2, 12001] loss: 0.66955
[  2, 12501] loss: 0.64048
[  2, 13001] loss: 0.65014
[  2, 13501] loss: 0.65205
[  2, 14001] loss: 0.62557
[  2, 14501] loss: 0.64243
[  2, 15001] loss: 0.63915
[  2, 15501] loss: 0.60774
[  2, 16001] loss: 0.63890
[  2, 16501] loss: 0.69538
[  2, 17001] loss: 0.68531
[  2, 17501] loss: 0.69528
[  2, 18001] loss: 0.68869
[  2, 18501] loss: 0.68366
[  2, 19001] loss: 0.65635
[  2, 19501] loss: 0.60155
[  2, 20001] loss: 0.62513
[  2, 20501] loss: 0.59528
[  2, 21001] loss: 0.61226
[  2, 21501] loss: 0.65775
[  2, 22001] loss: 0.62628
[  2, 22501] loss: 0.65247
[  2, 23001] loss: 0.67885
[  2, 23501] loss: 0.70576
[  2, 24001] loss: 0.73795
[  2, 24501] loss: 0.71176
Finished training
Accuracy on train: 0.56996
Accuracy on test: 0.52272
