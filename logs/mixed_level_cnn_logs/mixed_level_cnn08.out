{'word_context': 15, 'word_embed_size': 200, 'word_conv_units': 10, 'hidden_units': 5, 'dropout': True, 'batch_size': 500}
2482
train set done
test set done
[  1,     1] loss: 1.01840
[  1,   501] loss: 0.88528
[  1,  1001] loss: 0.90313
[  1,  1501] loss: 0.80016
[  1,  2001] loss: 0.78247
[  1,  2501] loss: 0.79960
[  1,  3001] loss: 0.79459
[  1,  3501] loss: 0.83396
[  1,  4001] loss: 0.79159
[  1,  4501] loss: 0.83185
[  1,  5001] loss: 0.79907
[  1,  5501] loss: 0.77102
[  1,  6001] loss: 0.74911
[  1,  6501] loss: 0.73437
[  1,  7001] loss: 0.75164
[  1,  7501] loss: 0.79074
[  1,  8001] loss: 0.72927
[  1,  8501] loss: 0.75514
[  1,  9001] loss: 0.76146
[  1,  9501] loss: 0.76556
[  1, 10001] loss: 0.75667
[  1, 10501] loss: 0.76168
[  1, 11001] loss: 0.73929
[  1, 11501] loss: 0.70808
[  1, 12001] loss: 0.72419
[  1, 12501] loss: 0.72345
[  1, 13001] loss: 0.72804
[  1, 13501] loss: 0.73150
[  1, 14001] loss: 0.73521
[  1, 14501] loss: 0.70066
[  1, 15001] loss: 0.72199
[  1, 15501] loss: 0.74296
[  1, 16001] loss: 0.70832
[  1, 16501] loss: 0.73061
[  1, 17001] loss: 0.74174
[  1, 17501] loss: 0.73604
[  1, 18001] loss: 0.70467
[  1, 18501] loss: 0.74028
[  1, 19001] loss: 0.71146
[  1, 19501] loss: 0.73985
[  1, 20001] loss: 0.72260
[  1, 20501] loss: 0.70307
[  1, 21001] loss: 0.72883
[  1, 21501] loss: 0.70555
[  1, 22001] loss: 0.71934
[  1, 22501] loss: 0.70456
[  1, 23001] loss: 0.70654
[  1, 23501] loss: 0.68182
[  1, 24001] loss: 0.72939
[  1, 24501] loss: 0.71996
[  2,     1] loss: 0.71618
[  2,   501] loss: 0.70057
[  2,  1001] loss: 0.71780
[  2,  1501] loss: 0.74227
[  2,  2001] loss: 0.72500
[  2,  2501] loss: 0.68254
[  2,  3001] loss: 0.67998
[  2,  3501] loss: 0.69808
[  2,  4001] loss: 0.70052
[  2,  4501] loss: 0.70045
[  2,  5001] loss: 0.70083
[  2,  5501] loss: 0.69435
[  2,  6001] loss: 0.68406
[  2,  6501] loss: 0.68623
[  2,  7001] loss: 0.66642
[  2,  7501] loss: 0.67322
[  2,  8001] loss: 0.67343
[  2,  8501] loss: 0.69583
[  2,  9001] loss: 0.70115
[  2,  9501] loss: 0.69843
[  2, 10001] loss: 0.67109
[  2, 10501] loss: 0.69482
[  2, 11001] loss: 0.68358
[  2, 11501] loss: 0.70046
[  2, 12001] loss: 0.70326
[  2, 12501] loss: 0.70223
[  2, 13001] loss: 0.66950
[  2, 13501] loss: 0.68501
[  2, 14001] loss: 0.67443
[  2, 14501] loss: 0.66960
[  2, 15001] loss: 0.67702
[  2, 15501] loss: 0.70096
[  2, 16001] loss: 0.65201
[  2, 16501] loss: 0.67354
[  2, 17001] loss: 0.67032
[  2, 17501] loss: 0.68611
[  2, 18001] loss: 0.68602
[  2, 18501] loss: 0.67620
[  2, 19001] loss: 0.68190
[  2, 19501] loss: 0.67458
[  2, 20001] loss: 0.68818
[  2, 20501] loss: 0.65656
[  2, 21001] loss: 0.68013
[  2, 21501] loss: 0.67764
[  2, 22001] loss: 0.67658
[  2, 22501] loss: 0.65524
[  2, 23001] loss: 0.68660
[  2, 23501] loss: 0.67091
[  2, 24001] loss: 0.67681
[  2, 24501] loss: 0.66433
[  3,     1] loss: 0.66703
[  3,   501] loss: 0.71052
[  3,  1001] loss: 0.68570
[  3,  1501] loss: 0.67622
[  3,  2001] loss: 0.67496
[  3,  2501] loss: 0.67365
[  3,  3001] loss: 0.66699
[  3,  3501] loss: 0.67960
[  3,  4001] loss: 0.65618
[  3,  4501] loss: 0.70134
[  3,  5001] loss: 0.66421
[  3,  5501] loss: 0.66397
[  3,  6001] loss: 0.66056
[  3,  6501] loss: 0.64909
[  3,  7001] loss: 0.65982
[  3,  7501] loss: 0.66329
[  3,  8001] loss: 0.64633
[  3,  8501] loss: 0.69863
[  3,  9001] loss: 0.65765
[  3,  9501] loss: 0.64689
[  3, 10001] loss: 0.65393
[  3, 10501] loss: 0.65608
[  3, 11001] loss: 0.66648
[  3, 11501] loss: 0.66959
[  3, 12001] loss: 0.66356
[  3, 12501] loss: 0.66375
[  3, 13001] loss: 0.65428
[  3, 13501] loss: 0.65569
[  3, 14001] loss: 0.66995
[  3, 14501] loss: 0.63747
[  3, 15001] loss: 0.64821
[  3, 15501] loss: 0.66810
[  3, 16001] loss: 0.67035
[  3, 16501] loss: 0.66900
[  3, 17001] loss: 0.69006
[  3, 17501] loss: 0.68178
[  3, 18001] loss: 0.65679
[  3, 18501] loss: 0.65106
[  3, 19001] loss: 0.65121
[  3, 19501] loss: 0.66184
[  3, 20001] loss: 0.67465
[  3, 20501] loss: 0.64871
[  3, 21001] loss: 0.64467
[  3, 21501] loss: 0.66030
[  3, 22001] loss: 0.65166
[  3, 22501] loss: 0.65082
[  3, 23001] loss: 0.65919
[  3, 23501] loss: 0.64365
[  3, 24001] loss: 0.68099
[  3, 24501] loss: 0.65538
[  4,     1] loss: 0.62882
[  4,   501] loss: 0.65061
[  4,  1001] loss: 0.67483
[  4,  1501] loss: 0.66668
[  4,  2001] loss: 0.65154
[  4,  2501] loss: 0.66068
[  4,  3001] loss: 0.64283
[  4,  3501] loss: 0.65179
[  4,  4001] loss: 0.64152
[  4,  4501] loss: 0.67204
[  4,  5001] loss: 0.64274
[  4,  5501] loss: 0.64731
[  4,  6001] loss: 0.66458
[  4,  6501] loss: 0.64141
[  4,  7001] loss: 0.63746
[  4,  7501] loss: 0.64937
[  4,  8001] loss: 0.63144
[  4,  8501] loss: 0.64464
[  4,  9001] loss: 0.63120
[  4,  9501] loss: 0.64487
[  4, 10001] loss: 0.63059
[  4, 10501] loss: 0.65052
[  4, 11001] loss: 0.64164
[  4, 11501] loss: 0.66334
[  4, 12001] loss: 0.64928
[  4, 12501] loss: 0.65848
[  4, 13001] loss: 0.64263
[  4, 13501] loss: 0.65528
[  4, 14001] loss: 0.64578
[  4, 14501] loss: 0.66803
[  4, 15001] loss: 0.64800
[  4, 15501] loss: 0.65562
[  4, 16001] loss: 0.66160
[  4, 16501] loss: 0.64480
[  4, 17001] loss: 0.65197
[  4, 17501] loss: 0.62625
[  4, 18001] loss: 0.63837
[  4, 18501] loss: 0.63278
[  4, 19001] loss: 0.63184
[  4, 19501] loss: 0.65639
[  4, 20001] loss: 0.63470
[  4, 20501] loss: 0.64231
[  4, 21001] loss: 0.67381
[  4, 21501] loss: 0.64024
[  4, 22001] loss: 0.63836
[  4, 22501] loss: 0.63827
[  4, 23001] loss: 0.64725
[  4, 23501] loss: 0.63545
[  4, 24001] loss: 0.65171
[  4, 24501] loss: 0.66522
[  5,     1] loss: 0.65655
[  5,   501] loss: 0.66501
[  5,  1001] loss: 0.67640
[  5,  1501] loss: 0.64190
[  5,  2001] loss: 0.64220
[  5,  2501] loss: 0.65570
[  5,  3001] loss: 0.64715
[  5,  3501] loss: 0.67909
[  5,  4001] loss: 0.64728
[  5,  4501] loss: 0.65051
[  5,  5001] loss: 0.63369
[  5,  5501] loss: 0.64622
[  5,  6001] loss: 0.65070
[  5,  6501] loss: 0.62156
[  5,  7001] loss: 0.62804
[  5,  7501] loss: 0.63109
[  5,  8001] loss: 0.59376
[  5,  8501] loss: 0.66273
[  5,  9001] loss: 0.64664
[  5,  9501] loss: 0.65010
[  5, 10001] loss: 0.60954
[  5, 10501] loss: 0.62938
[  5, 11001] loss: 0.62999
[  5, 11501] loss: 0.63116
[  5, 12001] loss: 0.64452
[  5, 12501] loss: 0.64169
[  5, 13001] loss: 0.61447
[  5, 13501] loss: 0.66889
[  5, 14001] loss: 0.63227
[  5, 14501] loss: 0.62514
[  5, 15001] loss: 0.64043
[  5, 15501] loss: 0.63882
[  5, 16001] loss: 0.63619
[  5, 16501] loss: 0.61368
[  5, 17001] loss: 0.63124
[  5, 17501] loss: 0.64380
[  5, 18001] loss: 0.64347
[  5, 18501] loss: 0.63490
[  5, 19001] loss: 0.62038
[  5, 19501] loss: 0.62425
[  5, 20001] loss: 0.64805
[  5, 20501] loss: 0.63273
[  5, 21001] loss: 0.64591
[  5, 21501] loss: 0.62461
[  5, 22001] loss: 0.62377
[  5, 22501] loss: 0.60438
[  5, 23001] loss: 0.63230
[  5, 23501] loss: 0.62489
[  5, 24001] loss: 0.63350
[  5, 24501] loss: 0.63267
[  6,     1] loss: 0.66399
[  6,   501] loss: 0.66557
[  6,  1001] loss: 0.64601
[  6,  1501] loss: 0.62465
[  6,  2001] loss: 0.64240
[  6,  2501] loss: 0.65463
[  6,  3001] loss: 0.62767
[  6,  3501] loss: 0.64246
[  6,  4001] loss: 0.61698
[  6,  4501] loss: 0.63492
[  6,  5001] loss: 0.61625
[  6,  5501] loss: 0.61131
[  6,  6001] loss: 0.62853
[  6,  6501] loss: 0.61700
[  6,  7001] loss: 0.62459
[  6,  7501] loss: 0.60213
[  6,  8001] loss: 0.60620
[  6,  8501] loss: 0.65070
[  6,  9001] loss: 0.63951
[  6,  9501] loss: 0.61598
[  6, 10001] loss: 0.62379
[  6, 10501] loss: 0.61214
[  6, 11001] loss: 0.61977
[  6, 11501] loss: 0.64527
[  6, 12001] loss: 0.62360
[  6, 12501] loss: 0.62498
[  6, 13001] loss: 0.61194
[  6, 13501] loss: 0.62277
[  6, 14001] loss: 0.60196
[  6, 14501] loss: 0.59647
[  6, 15001] loss: 0.62204
[  6, 15501] loss: 0.65419
[  6, 16001] loss: 0.60052
[  6, 16501] loss: 0.59936
[  6, 17001] loss: 0.63349
[  6, 17501] loss: 0.61105
[  6, 18001] loss: 0.61856
[  6, 18501] loss: 0.61615
[  6, 19001] loss: 0.59702
[  6, 19501] loss: 0.62753
[  6, 20001] loss: 0.59318
[  6, 20501] loss: 0.59353
[  6, 21001] loss: 0.63105
[  6, 21501] loss: 0.61213
[  6, 22001] loss: 0.61935
[  6, 22501] loss: 0.59781
[  6, 23001] loss: 0.61959
[  6, 23501] loss: 0.58877
[  6, 24001] loss: 0.61405
[  6, 24501] loss: 0.61947
[  7,     1] loss: 0.63472
[  7,   501] loss: 0.66811
[  7,  1001] loss: 0.63724
[  7,  1501] loss: 0.61246
[  7,  2001] loss: 0.62181
[  7,  2501] loss: 0.62672
[  7,  3001] loss: 0.60394
[  7,  3501] loss: 0.62243
[  7,  4001] loss: 0.61949
[  7,  4501] loss: 0.63326
[  7,  5001] loss: 0.59549
[  7,  5501] loss: 0.60331
[  7,  6001] loss: 0.62639
[  7,  6501] loss: 0.59382
[  7,  7001] loss: 0.62055
[  7,  7501] loss: 0.62291
[  7,  8001] loss: 0.60766
[  7,  8501] loss: 0.64933
[  7,  9001] loss: 0.60389
[  7,  9501] loss: 0.60153
[  7, 10001] loss: 0.61106
[  7, 10501] loss: 0.63661
[  7, 11001] loss: 0.59713
[  7, 11501] loss: 0.61063
[  7, 12001] loss: 0.61046
[  7, 12501] loss: 0.64437
[  7, 13001] loss: 0.56755
[  7, 13501] loss: 0.62077
[  7, 14001] loss: 0.59699
[  7, 14501] loss: 0.59037
[  7, 15001] loss: 0.61555
[  7, 15501] loss: 0.62325
[  7, 16001] loss: 0.60774
[  7, 16501] loss: 0.60149
[  7, 17001] loss: 0.63179
[  7, 17501] loss: 0.59780
[  7, 18001] loss: 0.63330
[  7, 18501] loss: 0.62263
[  7, 19001] loss: 0.60616
[  7, 19501] loss: 0.61055
[  7, 20001] loss: 0.59120
[  7, 20501] loss: 0.61115
[  7, 21001] loss: 0.64272
[  7, 21501] loss: 0.61044
[  7, 22001] loss: 0.60952
[  7, 22501] loss: 0.61018
[  7, 23001] loss: 0.62122
[  7, 23501] loss: 0.57300
[  7, 24001] loss: 0.62850
[  7, 24501] loss: 0.61482
Finished training
Accuracy on train: 0.69840
Accuracy on test: 0.56446
