{'word_context': 31, 'word_embed_size': 500, 'word_conv_units': 10, 'hidden_units': 5, 'dropout': True, 'batch_size': 500}
2482
train set done
test set done
[  1,     1] loss: 0.79693
[  1,   501] loss: 1.19006
[  1,  1001] loss: 4.46766
[  1,  1501] loss: 1.39414
[  1,  2001] loss: 1.10440
[  1,  2501] loss: 0.87747
[  1,  3001] loss: 0.83758
[  1,  3501] loss: 0.78016
[  1,  4001] loss: 0.77059
[  1,  4501] loss: 0.77628
[  1,  5001] loss: 0.75496
[  1,  5501] loss: 0.79762
[  1,  6001] loss: 0.84858
[  1,  6501] loss: 0.90367
[  1,  7001] loss: 0.84657
[  1,  7501] loss: 0.76133
[  1,  8001] loss: 0.71668
[  1,  8501] loss: 0.76843
[  1,  9001] loss: 0.77095
[  1,  9501] loss: 0.75127
[  1, 10001] loss: 0.76156
[  1, 10501] loss: 0.75949
[  1, 11001] loss: 0.76952
[  1, 11501] loss: 0.73111
[  1, 12001] loss: 0.76002
[  1, 12501] loss: 0.74783
[  1, 13001] loss: 0.74575
[  1, 13501] loss: 0.75218
[  1, 14001] loss: 0.78031
[  1, 14501] loss: 0.80287
[  1, 15001] loss: 0.71322
[  1, 15501] loss: 0.81430
[  1, 16001] loss: 0.77452
[  1, 16501] loss: 0.76322
[  1, 17001] loss: 0.79208
[  1, 17501] loss: 0.78284
[  1, 18001] loss: 0.79384
[  1, 18501] loss: 0.74970
[  1, 19001] loss: 0.75911
[  1, 19501] loss: 0.73062
[  1, 20001] loss: 0.74253
[  1, 20501] loss: 0.76421
[  1, 21001] loss: 0.72328
[  1, 21501] loss: 0.75716
[  1, 22001] loss: 0.72800
[  1, 22501] loss: 0.71127
[  1, 23001] loss: 0.83454
[  1, 23501] loss: 0.88014
[  1, 24001] loss: 0.80254
[  1, 24501] loss: 0.73803
[  2,     1] loss: 0.70492
[  2,   501] loss: 0.73070
[  2,  1001] loss: 0.71739
[  2,  1501] loss: 0.75090
[  2,  2001] loss: 0.73899
[  2,  2501] loss: 0.71822
[  2,  3001] loss: 0.70603
[  2,  3501] loss: 0.72035
[  2,  4001] loss: 0.70857
[  2,  4501] loss: 0.71435
[  2,  5001] loss: 0.73780
[  2,  5501] loss: 0.74060
[  2,  6001] loss: 0.72847
[  2,  6501] loss: 0.69513
[  2,  7001] loss: 0.70041
[  2,  7501] loss: 0.69584
[  2,  8001] loss: 0.70133
[  2,  8501] loss: 0.72877
[  2,  9001] loss: 0.71296
[  2,  9501] loss: 0.67858
[  2, 10001] loss: 0.69341
[  2, 10501] loss: 0.68782
[  2, 11001] loss: 0.68511
[  2, 11501] loss: 0.70189
[  2, 12001] loss: 0.71670
[  2, 12501] loss: 0.66065
[  2, 13001] loss: 0.69398
[  2, 13501] loss: 0.69125
[  2, 14001] loss: 0.69636
[  2, 14501] loss: 0.68671
[  2, 15001] loss: 0.68949
[  2, 15501] loss: 0.70426
[  2, 16001] loss: 0.69260
[  2, 16501] loss: 0.64358
[  2, 17001] loss: 0.64997
[  2, 17501] loss: 0.67759
[  2, 18001] loss: 0.64951
[  2, 18501] loss: 0.68801
[  2, 19001] loss: 0.68331
[  2, 19501] loss: 0.68479
[  2, 20001] loss: 0.70582
[  2, 20501] loss: 0.66787
[  2, 21001] loss: 0.67656
[  2, 21501] loss: 0.67355
[  2, 22001] loss: 0.66774
[  2, 22501] loss: 0.69392
[  2, 23001] loss: 0.67244
[  2, 23501] loss: 0.67375
[  2, 24001] loss: 0.66671
[  2, 24501] loss: 0.66126
Finished training
Accuracy on train: 0.67456
Accuracy on test: 0.56296
