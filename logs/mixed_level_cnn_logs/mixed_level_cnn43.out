{'word_context': 31, 'word_embed_size': 200, 'word_conv_units': 500, 'hidden_units': 5, 'dropout': True, 'batch_size': 500}
2482
train set done
test set done
[  1,     1] loss: 0.88836
[  1,   501] loss: 6.99674
[  1,  1001] loss: 6.02859
[  1,  1501] loss: 4.46751
[  1,  2001] loss: 4.02920
[  1,  2501] loss: 3.34243
[  1,  3001] loss: 2.42666
[  1,  3501] loss: 2.65845
[  1,  4001] loss: 2.22271
[  1,  4501] loss: 2.40182
[  1,  5001] loss: 1.68309
[  1,  5501] loss: 1.72542
[  1,  6001] loss: 1.30925
[  1,  6501] loss: 1.38690
[  1,  7001] loss: 1.34064
[  1,  7501] loss: 1.35434
[  1,  8001] loss: 1.48474
[  1,  8501] loss: 1.16120
[  1,  9001] loss: 0.95623
[  1,  9501] loss: 0.82073
[  1, 10001] loss: 0.79102
[  1, 10501] loss: 0.81461
[  1, 11001] loss: 0.77596
[  1, 11501] loss: 0.75018
[  1, 12001] loss: 0.75195
[  1, 12501] loss: 0.75825
[  1, 13001] loss: 0.77189
[  1, 13501] loss: 0.76845
[  1, 14001] loss: 0.77676
[  1, 14501] loss: 0.72367
[  1, 15001] loss: 0.75181
[  1, 15501] loss: 0.69787
[  1, 16001] loss: 0.70992
[  1, 16501] loss: 0.70316
[  1, 17001] loss: 0.73517
[  1, 17501] loss: 0.83100
[  1, 18001] loss: 0.88260
[  1, 18501] loss: 0.90571
[  1, 19001] loss: 0.76562
[  1, 19501] loss: 0.76662
[  1, 20001] loss: 0.73226
[  1, 20501] loss: 0.80755
[  1, 21001] loss: 0.79239
[  1, 21501] loss: 0.73433
[  1, 22001] loss: 0.70837
[  1, 22501] loss: 0.73320
[  1, 23001] loss: 0.71056
[  1, 23501] loss: 0.69191
[  1, 24001] loss: 0.68204
[  1, 24501] loss: 0.69067
[  2,     1] loss: 0.65962
[  2,   501] loss: 0.67105
[  2,  1001] loss: 0.66260
[  2,  1501] loss: 0.69354
[  2,  2001] loss: 0.70050
[  2,  2501] loss: 0.73640
[  2,  3001] loss: 0.67578
[  2,  3501] loss: 0.67892
[  2,  4001] loss: 0.68687
[  2,  4501] loss: 0.73135
[  2,  5001] loss: 0.71340
[  2,  5501] loss: 0.68230
[  2,  6001] loss: 0.62891
[  2,  6501] loss: 0.60709
[  2,  7001] loss: 0.60888
[  2,  7501] loss: 0.65300
[  2,  8001] loss: 0.73411
[  2,  8501] loss: 0.78863
[  2,  9001] loss: 0.71174
[  2,  9501] loss: 0.68261
[  2, 10001] loss: 0.63557
[  2, 10501] loss: 0.67016
[  2, 11001] loss: 0.68994
[  2, 11501] loss: 0.66543
[  2, 12001] loss: 0.63758
[  2, 12501] loss: 0.62646
[  2, 13001] loss: 0.64738
[  2, 13501] loss: 0.65509
[  2, 14001] loss: 0.63402
[  2, 14501] loss: 0.58665
[  2, 15001] loss: 0.59676
[  2, 15501] loss: 0.57423
[  2, 16001] loss: 0.54009
[  2, 16501] loss: 0.55511
[  2, 17001] loss: 0.55313
[  2, 17501] loss: 0.62707
[  2, 18001] loss: 0.74215
[  2, 18501] loss: 0.95871
[  2, 19001] loss: 1.09806
[  2, 19501] loss: 0.83943
[  2, 20001] loss: 0.73573
[  2, 20501] loss: 0.65083
[  2, 21001] loss: 0.63517
[  2, 21501] loss: 0.64244
[  2, 22001] loss: 0.68116
[  2, 22501] loss: 0.64043
[  2, 23001] loss: 0.64638
[  2, 23501] loss: 0.66558
[  2, 24001] loss: 0.65005
[  2, 24501] loss: 0.62748
Finished training
Accuracy on train: 0.77252
Accuracy on test: 0.56208
