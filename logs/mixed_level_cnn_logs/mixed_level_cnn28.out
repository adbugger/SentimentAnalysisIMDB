{'word_context': 101, 'word_embed_size': 200, 'word_conv_units': 10, 'hidden_units': 5, 'dropout': False, 'batch_size': 500}
2482
train set done
test set done
[  1,     1] loss: 0.70828
[  1,   501] loss: 1.60328
[  1,  1001] loss: 22.86594
[  1,  1501] loss: 0.79637
[  1,  2001] loss: 1.67308
[  1,  2501] loss: 2.12158
[  1,  3001] loss: 1.73096
[  1,  3501] loss: 1.55484
[  1,  4001] loss: 1.79729
[  1,  4501] loss: 1.75465
[  1,  5001] loss: 1.46348
[  1,  5501] loss: 1.54766
[  1,  6001] loss: 1.56675
[  1,  6501] loss: 1.30300
[  1,  7001] loss: 1.60279
[  1,  7501] loss: 1.19161
[  1,  8001] loss: 1.25792
[  1,  8501] loss: 1.36399
[  1,  9001] loss: 1.47732
[  1,  9501] loss: 1.20318
[  1, 10001] loss: 1.34981
[  1, 10501] loss: 1.30478
[  1, 11001] loss: 1.27382
[  1, 11501] loss: 1.21429
[  1, 12001] loss: 1.13425
[  1, 12501] loss: 1.22469
[  1, 13001] loss: 1.08364
[  1, 13501] loss: 0.97619
[  1, 14001] loss: 0.92104
[  1, 14501] loss: 0.95199
[  1, 15001] loss: 1.08079
[  1, 15501] loss: 1.04562
[  1, 16001] loss: 1.08259
[  1, 16501] loss: 1.09206
[  1, 17001] loss: 0.90387
[  1, 17501] loss: 0.89371
[  1, 18001] loss: 0.85442
[  1, 18501] loss: 0.79923
[  1, 19001] loss: 0.84893
[  1, 19501] loss: 0.96505
[  1, 20001] loss: 1.08751
[  1, 20501] loss: 0.92852
[  1, 21001] loss: 0.97319
[  1, 21501] loss: 1.07773
[  1, 22001] loss: 0.98504
[  1, 22501] loss: 0.87072
[  1, 23001] loss: 0.85096
[  1, 23501] loss: 0.93524
[  1, 24001] loss: 1.00776
[  1, 24501] loss: 1.03428
[  2,     1] loss: 0.98549
[  2,   501] loss: 0.90667
[  2,  1001] loss: 0.81830
[  2,  1501] loss: 0.78030
[  2,  2001] loss: 0.75694
[  2,  2501] loss: 0.75049
[  2,  3001] loss: 0.69411
[  2,  3501] loss: 0.70254
[  2,  4001] loss: 0.67754
[  2,  4501] loss: 0.68005
[  2,  5001] loss: 0.65595
[  2,  5501] loss: 0.63876
[  2,  6001] loss: 0.62015
[  2,  6501] loss: 0.68116
[  2,  7001] loss: 0.70357
[  2,  7501] loss: 0.98422
[  2,  8001] loss: 1.15966
[  2,  8501] loss: 1.14402
[  2,  9001] loss: 1.04669
[  2,  9501] loss: 1.08041
[  2, 10001] loss: 0.96819
[  2, 10501] loss: 0.84768
[  2, 11001] loss: 0.93786
[  2, 11501] loss: 0.93051
[  2, 12001] loss: 0.96359
[  2, 12501] loss: 0.88651
[  2, 13001] loss: 0.95484
[  2, 13501] loss: 1.00325
[  2, 14001] loss: 1.00697
[  2, 14501] loss: 1.05955
[  2, 15001] loss: 0.76113
[  2, 15501] loss: 0.86190
[  2, 16001] loss: 0.91121
[  2, 16501] loss: 0.90205
[  2, 17001] loss: 0.99832
[  2, 17501] loss: 0.99933
[  2, 18001] loss: 0.91416
[  2, 18501] loss: 0.93643
[  2, 19001] loss: 0.84463
[  2, 19501] loss: 0.75374
[  2, 20001] loss: 0.70574
[  2, 20501] loss: 0.78228
[  2, 21001] loss: 0.77867
[  2, 21501] loss: 0.77081
[  2, 22001] loss: 0.81019
[  2, 22501] loss: 0.81868
[  2, 23001] loss: 0.83952
[  2, 23501] loss: 0.75549
[  2, 24001] loss: 0.71322
[  2, 24501] loss: 0.74087
Finished training
Accuracy on train: 0.71116
Accuracy on test: 0.54696
