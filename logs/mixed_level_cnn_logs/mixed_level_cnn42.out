{'word_context': 31, 'word_embed_size': 200, 'word_conv_units': 100, 'hidden_units': 5, 'dropout': True, 'batch_size': 500}
2482
train set done
test set done
[  1,     1] loss: 0.84229
[  1,   501] loss: 0.87977
[  1,  1001] loss: 2.04201
[  1,  1501] loss: 3.29401
[  1,  2001] loss: 1.77016
[  1,  2501] loss: 3.21717
[  1,  3001] loss: 1.74892
[  1,  3501] loss: 1.55549
[  1,  4001] loss: 1.03330
[  1,  4501] loss: 1.21381
[  1,  5001] loss: 1.19898
[  1,  5501] loss: 1.02050
[  1,  6001] loss: 0.84973
[  1,  6501] loss: 0.85829
[  1,  7001] loss: 0.74990
[  1,  7501] loss: 0.80799
[  1,  8001] loss: 0.85603
[  1,  8501] loss: 0.85178
[  1,  9001] loss: 0.83119
[  1,  9501] loss: 0.91168
[  1, 10001] loss: 0.87330
[  1, 10501] loss: 0.84706
[  1, 11001] loss: 0.83349
[  1, 11501] loss: 0.86038
[  1, 12001] loss: 0.82049
[  1, 12501] loss: 0.80357
[  1, 13001] loss: 0.78201
[  1, 13501] loss: 0.81196
[  1, 14001] loss: 0.76621
[  1, 14501] loss: 0.73518
[  1, 15001] loss: 0.73496
[  1, 15501] loss: 0.72696
[  1, 16001] loss: 0.70643
[  1, 16501] loss: 0.73233
[  1, 17001] loss: 0.75035
[  1, 17501] loss: 0.73839
[  1, 18001] loss: 0.74653
[  1, 18501] loss: 0.74447
[  1, 19001] loss: 0.73438
[  1, 19501] loss: 0.69799
[  1, 20001] loss: 0.73095
[  1, 20501] loss: 0.72925
[  1, 21001] loss: 0.74135
[  1, 21501] loss: 0.74478
[  1, 22001] loss: 0.73740
[  1, 22501] loss: 0.71676
[  1, 23001] loss: 0.74189
[  1, 23501] loss: 0.69405
[  1, 24001] loss: 0.71743
[  1, 24501] loss: 0.69305
[  2,     1] loss: 0.65192
[  2,   501] loss: 0.71112
[  2,  1001] loss: 0.71387
[  2,  1501] loss: 0.79296
[  2,  2001] loss: 0.78356
[  2,  2501] loss: 0.70801
[  2,  3001] loss: 0.71249
[  2,  3501] loss: 0.65158
[  2,  4001] loss: 0.69327
[  2,  4501] loss: 0.67684
[  2,  5001] loss: 0.65540
[  2,  5501] loss: 0.67153
[  2,  6001] loss: 0.70696
[  2,  6501] loss: 0.69256
[  2,  7001] loss: 0.69574
[  2,  7501] loss: 0.68773
[  2,  8001] loss: 0.64116
[  2,  8501] loss: 0.64189
[  2,  9001] loss: 0.64617
[  2,  9501] loss: 0.64713
[  2, 10001] loss: 0.63462
[  2, 10501] loss: 0.62708
[  2, 11001] loss: 0.64346
[  2, 11501] loss: 0.64595
[  2, 12001] loss: 0.67294
[  2, 12501] loss: 0.65243
[  2, 13001] loss: 0.66048
[  2, 13501] loss: 0.64632
[  2, 14001] loss: 0.62854
[  2, 14501] loss: 0.62687
[  2, 15001] loss: 0.66777
[  2, 15501] loss: 0.64015
[  2, 16001] loss: 0.66301
[  2, 16501] loss: 0.62927
[  2, 17001] loss: 0.62202
[  2, 17501] loss: 0.64168
[  2, 18001] loss: 0.64462
[  2, 18501] loss: 0.62318
[  2, 19001] loss: 0.61878
[  2, 19501] loss: 0.67936
[  2, 20001] loss: 0.80190
[  2, 20501] loss: 0.70129
[  2, 21001] loss: 0.65453
[  2, 21501] loss: 0.62455
[  2, 22001] loss: 0.61034
[  2, 22501] loss: 0.60474
[  2, 23001] loss: 0.60751
[  2, 23501] loss: 0.64679
[  2, 24001] loss: 0.59698
[  2, 24501] loss: 0.58360
Finished training
Accuracy on train: 0.77068
Accuracy on test: 0.59496
