{'word_context': 51, 'word_embed_size': 500, 'word_conv_units': 10, 'hidden_units': 5, 'dropout': False, 'batch_size': 500}
2482
train set done
test set done
[  1,     1] loss: 0.75623
[  1,   501] loss: 2.52880
[  1,  1001] loss: 32.05830
[  1,  1501] loss: 0.75076
[  1,  2001] loss: 1.33891
[  1,  2501] loss: 6.08206
[  1,  3001] loss: 0.84436
[  1,  3501] loss: 2.02873
[  1,  4001] loss: 2.78486
[  1,  4501] loss: 1.53247
[  1,  5001] loss: 1.95783
[  1,  5501] loss: 1.80509
[  1,  6001] loss: 1.74354
[  1,  6501] loss: 1.54748
[  1,  7001] loss: 1.66104
[  1,  7501] loss: 1.59566
[  1,  8001] loss: 1.41345
[  1,  8501] loss: 1.21586
[  1,  9001] loss: 1.21680
[  1,  9501] loss: 1.23225
[  1, 10001] loss: 1.22696
[  1, 10501] loss: 1.08243
[  1, 11001] loss: 1.14679
[  1, 11501] loss: 1.10171
[  1, 12001] loss: 1.11638
[  1, 12501] loss: 1.10664
[  1, 13001] loss: 1.25721
[  1, 13501] loss: 1.10313
[  1, 14001] loss: 1.03571
[  1, 14501] loss: 1.13270
[  1, 15001] loss: 1.22458
[  1, 15501] loss: 1.24818
[  1, 16001] loss: 1.28337
[  1, 16501] loss: 1.19318
[  1, 17001] loss: 1.01883
[  1, 17501] loss: 0.99095
[  1, 18001] loss: 0.93042
[  1, 18501] loss: 0.98796
[  1, 19001] loss: 1.08051
[  1, 19501] loss: 1.02898
[  1, 20001] loss: 1.04157
[  1, 20501] loss: 0.97306
[  1, 21001] loss: 1.14357
[  1, 21501] loss: 1.10837
[  1, 22001] loss: 1.13915
[  1, 22501] loss: 1.12776
[  1, 23001] loss: 1.15162
[  1, 23501] loss: 1.29174
[  1, 24001] loss: 1.02662
[  1, 24501] loss: 1.03864
[  2,     1] loss: 1.06501
[  2,   501] loss: 1.56781
[  2,  1001] loss: 1.01558
[  2,  1501] loss: 1.22180
[  2,  2001] loss: 0.97613
[  2,  2501] loss: 0.85894
[  2,  3001] loss: 0.85743
[  2,  3501] loss: 0.85924
[  2,  4001] loss: 0.90322
[  2,  4501] loss: 0.85686
[  2,  5001] loss: 0.83988
[  2,  5501] loss: 0.83568
[  2,  6001] loss: 0.81907
[  2,  6501] loss: 0.82596
[  2,  7001] loss: 0.85814
[  2,  7501] loss: 0.93120
[  2,  8001] loss: 0.95029
[  2,  8501] loss: 0.80192
[  2,  9001] loss: 0.75155
[  2,  9501] loss: 0.77601
[  2, 10001] loss: 0.75540
[  2, 10501] loss: 0.74751
[  2, 11001] loss: 0.72784
[  2, 11501] loss: 0.70837
[  2, 12001] loss: 0.67698
[  2, 12501] loss: 0.75339
[  2, 13001] loss: 0.74290
[  2, 13501] loss: 0.76126
[  2, 14001] loss: 0.73074
[  2, 14501] loss: 0.78369
[  2, 15001] loss: 0.87307
[  2, 15501] loss: 0.97608
[  2, 16001] loss: 1.03889
[  2, 16501] loss: 0.85200
[  2, 17001] loss: 0.77089
[  2, 17501] loss: 0.71223
[  2, 18001] loss: 0.61215
[  2, 18501] loss: 0.64657
[  2, 19001] loss: 0.64712
[  2, 19501] loss: 0.62771
[  2, 20001] loss: 0.60157
[  2, 20501] loss: 0.59797
[  2, 21001] loss: 0.62196
[  2, 21501] loss: 0.62851
[  2, 22001] loss: 0.62862
[  2, 22501] loss: 0.62997
[  2, 23001] loss: 0.60376
[  2, 23501] loss: 0.72600
[  2, 24001] loss: 0.81032
[  2, 24501] loss: 1.10389
Finished training
Accuracy on train: 0.52688
Accuracy on test: 0.51224
